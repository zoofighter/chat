{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALM ë°ì´í„° ë¶„ì„ ì±—ë´‡\n",
    "## LM Studio Qwen + LangChain Function Calling\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë¡œì»¬ LM Studioì˜ Qwen ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ALM ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Report-Agent êµ¬í˜„ ê°€ì´ë“œ\n",
    "\n",
    "ì´ ê°€ì´ë“œëŠ” ALM ì±—ë´‡ì„ Report-Agentë¡œ ì§„í™”ì‹œí‚¤ê¸° ìœ„í•œ ë‹¨ê³„ë³„ êµ¬í˜„ ì§€ì¹¨ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì „ì²´ ê°€ì´ë“œëŠ” `docs/IMPLEMENTATION_GUIDE.md` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.**\n",
    "\n",
    "## êµ¬í˜„ ê°œìš”\n",
    "\n",
    "### Phase 1: ì‹œê°í™” + ê¸°ë³¸ ë¦¬í¬íŠ¸ ìƒì„± (7ê°œ ë„êµ¬)\n",
    "- âœ… Cell 10: `visualize_data()` í•¨ìˆ˜ ì¬í™œì„±í™”\n",
    "- âœ… Cell 8: `generate_comprehensive_report()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- âœ… Cell 10 ë‹¤ìŒ: `export_to_markdown()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- âœ… Cell 12: ë„êµ¬ 2ê°œ ì¶”ê°€ (visualize_data, generate_comprehensive_report)\n",
    "- âœ… Cell 19: SYSTEM_PROMPT ì—…ë°ì´íŠ¸\n",
    "\n",
    "### Phase 2: ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ + ì¶”ì„¸ ë¶„ì„ (9ê°œ ë„êµ¬)\n",
    "- â³ Cell 8: `compare_scenarios()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- â³ Cell 8: `analyze_trends()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- â³ Cell 12: ë„êµ¬ 2ê°œ ì¶”ê°€ (compare_scenarios, analyze_trends)\n",
    "- â³ Cell 19: SYSTEM_PROMPT ì—…ë°ì´íŠ¸\n",
    "\n",
    "### Phase 3: PDF/Excel ë‚´ë³´ë‚´ê¸° (10ê°œ ë„êµ¬)\n",
    "- â³ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: `reportlab`, `openpyxl`, `Pillow`\n",
    "- â³ Cell 10 ë‹¤ìŒ: `export_to_pdf()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- â³ Cell 10 ë‹¤ìŒ: `export_to_excel()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- â³ Cell 10 ë‹¤ìŒ: `export_report()` í•¨ìˆ˜ ì¶”ê°€\n",
    "- â³ Cell 12: ë„êµ¬ 1ê°œ ì¶”ê°€ (export_report)\n",
    "- â³ Cell 19: SYSTEM_PROMPT ì—…ë°ì´íŠ¸\n",
    "\n",
    "### Phase 4: Executive Summary + ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±\n",
    "- â³ Cell 15: ALMAgent í´ë˜ìŠ¤ í™•ì¥\n",
    "- â³ Cell 15: `_create_executive_summary()` ë©”ì„œë“œ ì¶”ê°€\n",
    "- â³ Cell 15: `_create_insights()` ë©”ì„œë“œ ì¶”ê°€\n",
    "- â³ Cell 15: `generate_report_with_insights()` ë©”ì„œë“œ ì¶”ê°€\n",
    "- â³ Cell 19: SYSTEM_PROMPT ìµœì¢… ì—…ë°ì´íŠ¸\n",
    "\n",
    "## ë¹ ë¥¸ ì‹œì‘\n",
    "\n",
    "1. **Phase 1ë¶€í„° ì‹œì‘**: ì•„ë˜ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ë©´ì„œ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”\n",
    "2. **ê° Phase ì™„ë£Œ í›„ í…ŒìŠ¤íŠ¸**: ì œê³µëœ í…ŒìŠ¤íŠ¸ ì½”ë“œë¡œ ë™ì‘ í™•ì¸\n",
    "3. **ë¬¸ì œ ë°œìƒ ì‹œ**: `docs/IMPLEMENTATION_GUIDE.md`ì˜ ìƒì„¸ ê°€ì´ë“œ ì°¸ì¡°\n",
    "\n",
    "## ìƒì„¸ êµ¬í˜„ ê°€ì´ë“œ\n",
    "\n",
    "ê° Phaseì˜ êµ¬ì²´ì ì¸ ì½”ë“œëŠ” `docs/IMPLEMENTATION_GUIDE.md` íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n",
    "í•´ë‹¹ íŒŒì¼ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ê° í•¨ìˆ˜ì˜ ì™„ì „í•œ ì½”ë“œ (ë³µì‚¬ & ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)\n",
    "- Pydantic ëª¨ë¸ ì •ì˜\n",
    "- Tool wrapper í•¨ìˆ˜\n",
    "- í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "- ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n",
    "\n",
    "---\n",
    "\n",
    "**ë‹¤ìŒ ì…€ë¶€í„° Phaseë³„ êµ¬í˜„ì„ ì‹œì‘í•©ë‹ˆë‹¤.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # MacOS\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\n",
      "\n",
      "orders_summary: 115ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: BASE_DATE, REFERENCE_NO, REFERENCE_SEQ, DESCRIPTION, CURRENCY_CD...\n",
      "\n",
      "ALM_INST: 115ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: BASE_DATE, REFERENCE_NO, REFERENCE_SEQ, DESCRIPTION, CURRENCY_CD...\n",
      "\n",
      "NFAT_LIQ_INDEX_SUMMARY_M: 12ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: BASE_DATE, RULE_NO, SCENARIO_NO, TIME_BAND_RULE_NO, DISPLAY_SEQ...\n",
      "\n",
      "NFAR_LIQ_GAP_310524: 43ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: RULE_NO, BASE_DATE, GAP_BASE_DATE, PROD_COA_CODE, TABLE_NAME...\n",
      "\n",
      "NFA_EXCH_RATE_HIST: 5ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: UNIT_CURRENCY_CD, CNVT_CURRENCY_CD, EFFECTIVE_DATE, EXCH_RATE, EXCH_RATE_STATUS_CD...\n",
      "\n",
      "NFA_IRC_RATE_HIST: 5ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: EFFECTIVE_DATE, INT_RATE_CD, INT_RATE_TERM, INT_RATE_TERM_MULT, INT_RATE...\n",
      "\n",
      "column_descriptions: 3ê°œ ì»¬ëŸ¼\n",
      "  ì£¼ìš” ì»¬ëŸ¼: table_name, column_name, description...\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ\n",
    "DB_PATH = 'simple.db'\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„±\"\"\"\n",
    "    return sqlite3.connect(DB_PATH)\n",
    "\n",
    "def get_table_info():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    table_info = {}\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        columns = cursor.fetchall()\n",
    "        table_info[table_name] = [col[1] for col in columns]  # ì»¬ëŸ¼ëª…ë§Œ ì¶”ì¶œ\n",
    "    \n",
    "    conn.close()\n",
    "    return table_info\n",
    "\n",
    "# í…Œì´ë¸” ì •ë³´ í™•ì¸\n",
    "tables = get_table_info()\n",
    "print(\"ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\")\n",
    "for table_name, columns in tables.items():\n",
    "    print(f\"\\n{table_name}: {len(columns)}ê°œ ì»¬ëŸ¼\")\n",
    "    print(f\"  ì£¼ìš” ì»¬ëŸ¼: {', '.join(columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LM Studio ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM Studio ì—°ê²° ì„¤ì • ì™„ë£Œ!\n",
      "Base URL: http://localhost:1234/v1\n"
     ]
    }
   ],
   "source": [
    "# LM Studio ì„¤ì •\n",
    "LM_STUDIO_BASE_URL = \"http://localhost:1234/v1\"\n",
    "LM_STUDIO_API_KEY = \"lm-studio\"  # LM StudioëŠ” ì‹¤ì œ API í‚¤ ë¶ˆí•„ìš”\n",
    "\n",
    "# LangChain ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” (LM Studio í˜¸í™˜)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=LM_STUDIO_BASE_URL,\n",
    "    api_key=LM_STUDIO_API_KEY,\n",
    "    temperature=0.1,\n",
    "    model=\"qwen\",  # LM Studioì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ëª…\n",
    ")\n",
    "\n",
    "print(\"LM Studio ì—°ê²° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"Base URL: {LM_STUDIO_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL ì‹¤í–‰ ë° ë¶„ì„ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n",
      "âœ“ Phase 1-3 ëª¨ë“  ë¦¬í¬íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def execute_sql_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "    \n",
    "    Args:\n",
    "        query: ì‹¤í–‰í•  SQL ì¿¼ë¦¬\n",
    "    \n",
    "    Returns:\n",
    "        ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (data, columns, row_count í¬í•¨)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": df.to_dict('records'),\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"row_count\": len(df),\n",
    "            \"dataframe\": df\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"data\": [],\n",
    "            \"columns\": [],\n",
    "            \"row_count\": 0\n",
    "        }\n",
    "\n",
    "def search_alm_contracts(filters: Optional[Dict] = None, limit: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    ALM ê³„ì•½ ì •ë³´ ê²€ìƒ‰\n",
    "    \n",
    "    Args:\n",
    "        filters: í•„í„° ì¡°ê±´ (ì˜ˆ: {\"CURRENCY_CD\": \"KRW\"})\n",
    "        limit: ê²°ê³¼ ì œí•œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"SELECT * FROM ALM_INST\"\n",
    "    \n",
    "    if filters:\n",
    "        conditions = [f\"{k} = '{v}'\" for k, v in filters.items()]\n",
    "        query += \" WHERE \" + \" AND \".join(conditions)\n",
    "    \n",
    "    query += f\" LIMIT {limit}\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ê²€ìƒ‰ ê²°ê³¼: {result['row_count']}ê±´\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def analyze_liquidity_gap(scenario_no: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "    \n",
    "    Args:\n",
    "        scenario_no: ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸\n",
    "    \n",
    "    Returns:\n",
    "        ë¶„ì„ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        TIME_BAND,\n",
    "        SUM(GAP_PRN_TOTAL) as ì´_ì›ê¸ˆê°­,\n",
    "        SUM(GAP_INT_TOTAL) as ì´_ì´ìê°­,\n",
    "        COUNT(*) as ê±´ìˆ˜\n",
    "    FROM NFAR_LIQ_GAP_310524\n",
    "    \"\"\"\n",
    "    \n",
    "    if scenario_no is not None:\n",
    "        query += f\" WHERE SCENARIO_NO = {scenario_no}\"\n",
    "    \n",
    "    query += \" GROUP BY TIME_BAND ORDER BY TIME_BAND\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ìœ ë™ì„± ê°­ ë¶„ì„ ê²°ê³¼:\\n\\n{df.to_string()}\\n\\nì´ {result['row_count']}ê°œ ê¸°ê°„ëŒ€\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_exchange_rate(currency: str, date: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    í™˜ìœ¨ ì •ë³´ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        currency: í†µí™” ì½”ë“œ (ì˜ˆ: USD, EUR)\n",
    "        date: ì¡°íšŒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)\n",
    "    \n",
    "    Returns:\n",
    "        í™˜ìœ¨ ì •ë³´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM NFA_EXCH_RATE_HIST WHERE UNIT_CURRENCY_CD = '{currency}'\"\n",
    "    \n",
    "    if date:\n",
    "        query += f\" AND EFFECTIVE_DATE = '{date}'\"\n",
    "    \n",
    "    query += \" ORDER BY EFFECTIVE_DATE DESC LIMIT 10\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"{currency} í™˜ìœ¨ ì •ë³´:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_interest_rate(rate_cd: int, term: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    ê¸ˆë¦¬ ì •ë³´ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        rate_cd: ê¸ˆë¦¬ ì½”ë“œ\n",
    "        term: ê¸ˆë¦¬ ê¸°ê°„\n",
    "    \n",
    "    Returns:\n",
    "        ê¸ˆë¦¬ ì •ë³´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM NFA_IRC_RATE_HIST WHERE INT_RATE_CD = {rate_cd}\"\n",
    "    \n",
    "    if term is not None:\n",
    "        query += f\" AND INT_RATE_TERM = {term}\"\n",
    "    \n",
    "    query += \" ORDER BY EFFECTIVE_DATE DESC LIMIT 10\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ê¸ˆë¦¬ ì •ë³´:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_aggregate_stats(table_name: str, group_by: str, aggregate_col: str) -> str:\n",
    "    \"\"\"\n",
    "    ì§‘ê³„ í†µê³„ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        table_name: í…Œì´ë¸”ëª…\n",
    "        group_by: ê·¸ë£¹í™” ì»¬ëŸ¼\n",
    "        aggregate_col: ì§‘ê³„ ì»¬ëŸ¼\n",
    "    \n",
    "    Returns:\n",
    "        í†µê³„ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        {group_by},\n",
    "        COUNT(*) as ê±´ìˆ˜,\n",
    "        SUM({aggregate_col}) as í•©ê³„,\n",
    "        AVG({aggregate_col}) as í‰ê· ,\n",
    "        MIN({aggregate_col}) as ìµœì†Œ,\n",
    "        MAX({aggregate_col}) as ìµœëŒ€\n",
    "    FROM {table_name}\n",
    "    GROUP BY {group_by}\n",
    "    ORDER BY í•©ê³„ DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"{table_name} í…Œì´ë¸” {group_by}ë³„ {aggregate_col} ì§‘ê³„:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "print(\"SQL í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Phase 1: ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n",
    "def generate_comprehensive_report(\n",
    "    include_sections: Optional[List[str]] = None,\n",
    "    scenario_no: Optional[int] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ì¢…í•© ALM ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (Phase 1)\n",
    "\n",
    "    Args:\n",
    "        include_sections: í¬í•¨í•  ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ì„¹ì…˜)\n",
    "        scenario_no: ìœ ë™ì„± ê°­ ë¶„ì„ì— ì‚¬ìš©í•  ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸\n",
    "\n",
    "    Returns:\n",
    "        ë¦¬í¬íŠ¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    report = {\n",
    "        'title': 'ALM ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸',\n",
    "        'generated_at': datetime.now(),\n",
    "        'sections': {},\n",
    "        'metadata': {\n",
    "            'scenario_no': scenario_no,\n",
    "            'requested_sections': include_sections\n",
    "        }\n",
    "    }\n",
    "\n",
    "    all_sections = ['data_overview', 'liquidity_gap', 'market_data', 'dimensional_analysis']\n",
    "    sections_to_include = include_sections if include_sections else all_sections\n",
    "\n",
    "    # 1. Data Overview\n",
    "    if 'data_overview' in sections_to_include:\n",
    "        query = \"\"\"\n",
    "        SELECT\n",
    "            CURRENCY_CD as í†µí™”,\n",
    "            COUNT(*) as ê³„ì•½ìˆ˜,\n",
    "            SUM(CUR_PAR_BAL) as ì´ì”ì•¡,\n",
    "            AVG(INT_RATE) as í‰ê· ê¸ˆë¦¬\n",
    "        FROM ALM_INST\n",
    "        GROUP BY CURRENCY_CD\n",
    "        ORDER BY ì´ì”ì•¡ DESC\n",
    "        \"\"\"\n",
    "        result = execute_sql_query(query)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            report['sections']['data_overview'] = {\n",
    "                'title': 'ë°ì´í„° ê°œìš”',\n",
    "                'data': result['data'],\n",
    "                'summary': f\"ì´ {sum([r['ê³„ì•½ìˆ˜'] for r in result['data']])}ê±´ì˜ ê³„ì•½, \"\n",
    "                          f\"{len(result['data'])}ê°œ í†µí™”\"\n",
    "            }\n",
    "\n",
    "    # 2. Liquidity Gap\n",
    "    if 'liquidity_gap' in sections_to_include:\n",
    "        query = \"\"\"\n",
    "        SELECT\n",
    "            TIME_BAND as ê¸°ê°„ëŒ€,\n",
    "            SUM(GAP_PRN_TOTAL) as ì›ê¸ˆê°­,\n",
    "            SUM(GAP_INT_TOTAL) as ì´ìê°­,\n",
    "            SUM(GAP_PRN_TOTAL + GAP_INT_TOTAL) as ì´ê°­\n",
    "        FROM NFAR_LIQ_GAP_310524\n",
    "        \"\"\"\n",
    "\n",
    "        if scenario_no is not None:\n",
    "            query += f\" WHERE SCENARIO_NO = {scenario_no}\"\n",
    "\n",
    "        query += \" GROUP BY TIME_BAND ORDER BY TIME_BAND\"\n",
    "\n",
    "        result = execute_sql_query(query)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            df = result['dataframe']\n",
    "            total_gap = df['ì´ê°­'].sum() if 'ì´ê°­' in df.columns else 0\n",
    "\n",
    "            report['sections']['liquidity_gap'] = {\n",
    "                'title': 'ìœ ë™ì„± ê°­ ë¶„ì„',\n",
    "                'data': result['data'],\n",
    "                'summary': f\"ì´ {result['row_count']}ê°œ ê¸°ê°„ëŒ€, ì´ê°­: {total_gap:,.0f}\",\n",
    "                'scenario_no': scenario_no\n",
    "            }\n",
    "\n",
    "    # 3. Market Data\n",
    "    if 'market_data' in sections_to_include:\n",
    "        exchange_query = \"\"\"\n",
    "        SELECT\n",
    "            UNIT_CURRENCY_CD as í†µí™”,\n",
    "            EFFECTIVE_DATE as ì¼ì,\n",
    "            EXCH_RATE as í™˜ìœ¨\n",
    "        FROM NFA_EXCH_RATE_HIST\n",
    "        WHERE UNIT_CURRENCY_CD IN ('USD', 'EUR', 'JPY', 'CNY')\n",
    "        ORDER BY EFFECTIVE_DATE DESC\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "\n",
    "        exchange_result = execute_sql_query(exchange_query)\n",
    "\n",
    "        interest_query = \"\"\"\n",
    "        SELECT\n",
    "            INT_RATE_CD as ê¸ˆë¦¬ì½”ë“œ,\n",
    "            INT_RATE_TERM as ê¸°ê°„,\n",
    "            EFFECTIVE_DATE as ì¼ì,\n",
    "            INT_RATE as ê¸ˆë¦¬\n",
    "        FROM NFA_IRC_RATE_HIST\n",
    "        ORDER BY EFFECTIVE_DATE DESC\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "\n",
    "        interest_result = execute_sql_query(interest_query)\n",
    "\n",
    "        report['sections']['market_data'] = {\n",
    "            'title': 'ì‹œì¥ ë°ì´í„°',\n",
    "            'exchange_rates': exchange_result['data'] if exchange_result['success'] else [],\n",
    "            'interest_rates': interest_result['data'] if interest_result['success'] else [],\n",
    "            'summary': f\"í™˜ìœ¨ {len(exchange_result['data'])}ê±´, ê¸ˆë¦¬ {len(interest_result['data'])}ê±´\"\n",
    "        }\n",
    "\n",
    "    # 4. Dimensional Analysis\n",
    "    if 'dimensional_analysis' in sections_to_include:\n",
    "        dim_query = \"\"\"\n",
    "        SELECT\n",
    "            ALM_DIMN_CD as ALMì°¨ì›,\n",
    "            COUNT(*) as ê±´ìˆ˜,\n",
    "            SUM(CUR_PAR_BAL) as ì´ì”ì•¡\n",
    "        FROM ALM_INST\n",
    "        GROUP BY ALM_DIMN_CD\n",
    "        ORDER BY ì´ì”ì•¡ DESC\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "\n",
    "        dim_result = execute_sql_query(dim_query)\n",
    "\n",
    "        report['sections']['dimensional_analysis'] = {\n",
    "            'title': 'ì°¨ì› ë¶„ì„',\n",
    "            'data': dim_result['data'] if dim_result['success'] else [],\n",
    "            'summary': f\"ì´ {len(dim_result['data'])}ê°œ ALM ì°¨ì›\"\n",
    "        }\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Phase 2: ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n",
    "def compare_scenarios(\n",
    "    scenario_list: List[int],\n",
    "    comparison_metrics: Optional[List[str]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ ë¶„ì„ (Phase 2)\n",
    "\n",
    "    Args:\n",
    "        scenario_list: ë¹„êµí•  ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸\n",
    "        comparison_metrics: ë¹„êµí•  ì§€í‘œ (Noneì´ë©´ ê¸°ë³¸ ì§€í‘œ)\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            'scenarios': List[int],\n",
    "            'comparison_data': Dict,\n",
    "            'summary': str\n",
    "        }\n",
    "    \"\"\"\n",
    "    comparison = {\n",
    "        'scenarios': scenario_list,\n",
    "        'comparison_data': {},\n",
    "        'summary': ''\n",
    "    }\n",
    "\n",
    "    for scenario_no in scenario_list:\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            TIME_BAND as ê¸°ê°„ëŒ€,\n",
    "            SUM(GAP_PRN_TOTAL) as ì›ê¸ˆê°­,\n",
    "            SUM(GAP_INT_TOTAL) as ì´ìê°­,\n",
    "            SUM(GAP_PRN_TOTAL + GAP_INT_TOTAL) as ì´ê°­\n",
    "        FROM NFAR_LIQ_GAP_310524\n",
    "        WHERE SCENARIO_NO = {scenario_no}\n",
    "        GROUP BY TIME_BAND\n",
    "        ORDER BY TIME_BAND\n",
    "        \"\"\"\n",
    "\n",
    "        result = execute_sql_query(query)\n",
    "\n",
    "        if result['success']:\n",
    "            df = result['dataframe']\n",
    "\n",
    "            comparison['comparison_data'][f'scenario_{scenario_no}'] = {\n",
    "                'data': result['data'],\n",
    "                'total_gap': df['ì´ê°­'].sum() if 'ì´ê°­' in df.columns else 0,\n",
    "                'max_gap': df['ì´ê°­'].max() if 'ì´ê°­' in df.columns else 0,\n",
    "                'min_gap': df['ì´ê°­'].min() if 'ì´ê°­' in df.columns else 0,\n",
    "                'avg_gap': df['ì´ê°­'].mean() if 'ì´ê°­' in df.columns else 0\n",
    "            }\n",
    "\n",
    "    summary_lines = []\n",
    "    summary_lines.append(f\"ì´ {len(scenario_list)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ\\n\")\n",
    "\n",
    "    for scenario_no in scenario_list:\n",
    "        key = f'scenario_{scenario_no}'\n",
    "        if key in comparison['comparison_data']:\n",
    "            data = comparison['comparison_data'][key]\n",
    "            summary_lines.append(\n",
    "                f\"ì‹œë‚˜ë¦¬ì˜¤ {scenario_no}: \"\n",
    "                f\"ì´ê°­={data['total_gap']:,.0f}, \"\n",
    "                f\"í‰ê· ={data['avg_gap']:,.0f}, \"\n",
    "                f\"ìµœëŒ€={data['max_gap']:,.0f}, \"\n",
    "                f\"ìµœì†Œ={data['min_gap']:,.0f}\"\n",
    "            )\n",
    "\n",
    "    comparison['summary'] = '\\n'.join(summary_lines)\n",
    "    return comparison\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Phase 2: ì¶”ì„¸ ë¶„ì„ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "\n",
    "def analyze_trends(\n",
    "    metric_type: str,\n",
    "    currency_or_rate_cd: Optional[str] = None,\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ì‹œê³„ì—´ ì¶”ì„¸ ë¶„ì„ (Phase 2)\n",
    "\n",
    "    Args:\n",
    "        metric_type: 'exchange_rate' ë˜ëŠ” 'interest_rate'\n",
    "        currency_or_rate_cd: í†µí™” ì½”ë“œ ë˜ëŠ” ê¸ˆë¦¬ ì½”ë“œ\n",
    "        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)\n",
    "        end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            'metric_type': str,\n",
    "            'data_points': List[Dict],\n",
    "            'statistics': Dict,\n",
    "            'trend': str\n",
    "        }\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    trends = {\n",
    "        'metric_type': metric_type,\n",
    "        'data_points': [],\n",
    "        'statistics': {},\n",
    "        'trend': ''\n",
    "    }\n",
    "\n",
    "    if metric_type == 'exchange_rate':\n",
    "        query = \"SELECT EFFECTIVE_DATE as ì¼ì, EXCH_RATE as ê°’ FROM NFA_EXCH_RATE_HIST\"\n",
    "\n",
    "        conditions = []\n",
    "        if currency_or_rate_cd:\n",
    "            conditions.append(f\"UNIT_CURRENCY_CD = '{currency_or_rate_cd}'\")\n",
    "        if start_date:\n",
    "            conditions.append(f\"EFFECTIVE_DATE >= '{start_date}'\")\n",
    "        if end_date:\n",
    "            conditions.append(f\"EFFECTIVE_DATE <= '{end_date}'\")\n",
    "\n",
    "        if conditions:\n",
    "            query += \" WHERE \" + \" AND \".join(conditions)\n",
    "\n",
    "        query += \" ORDER BY EFFECTIVE_DATE\"\n",
    "\n",
    "    elif metric_type == 'interest_rate':\n",
    "        query = \"SELECT EFFECTIVE_DATE as ì¼ì, INT_RATE as ê°’ FROM NFA_IRC_RATE_HIST\"\n",
    "\n",
    "        conditions = []\n",
    "        if currency_or_rate_cd:\n",
    "            conditions.append(f\"INT_RATE_CD = {currency_or_rate_cd}\")\n",
    "        if start_date:\n",
    "            conditions.append(f\"EFFECTIVE_DATE >= '{start_date}'\")\n",
    "        if end_date:\n",
    "            conditions.append(f\"EFFECTIVE_DATE <= '{end_date}'\")\n",
    "\n",
    "        if conditions:\n",
    "            query += \" WHERE \" + \" AND \".join(conditions)\n",
    "\n",
    "        query += \" ORDER BY EFFECTIVE_DATE\"\n",
    "\n",
    "    else:\n",
    "        return {\n",
    "            'error': f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” metric_type: {metric_type}\"\n",
    "        }\n",
    "\n",
    "    result = execute_sql_query(query)\n",
    "\n",
    "    if result['success'] and result['row_count'] > 0:\n",
    "        df = result['dataframe']\n",
    "        trends['data_points'] = result['data']\n",
    "\n",
    "        values = df['ê°’'].values\n",
    "        trends['statistics'] = {\n",
    "            'count': len(values),\n",
    "            'mean': float(np.mean(values)),\n",
    "            'std': float(np.std(values)),\n",
    "            'min': float(np.min(values)),\n",
    "            'max': float(np.max(values)),\n",
    "            'first_value': float(values[0]),\n",
    "            'last_value': float(values[-1]),\n",
    "            'change': float(values[-1] - values[0]),\n",
    "            'change_pct': float((values[-1] - values[0]) / values[0] * 100) if values[0] != 0 else 0\n",
    "        }\n",
    "\n",
    "        if len(values) >= 2:\n",
    "            x = np.arange(len(values))\n",
    "            slope = np.polyfit(x, values, 1)[0]\n",
    "\n",
    "            if slope > 0.01:\n",
    "                trends['trend'] = 'ìƒìŠ¹ ì¶”ì„¸'\n",
    "            elif slope < -0.01:\n",
    "                trends['trend'] = 'í•˜ë½ ì¶”ì„¸'\n",
    "            else:\n",
    "                trends['trend'] = 'ì•ˆì • ì¶”ì„¸'\n",
    "\n",
    "            trends['statistics']['slope'] = float(slope)\n",
    "\n",
    "    return trends\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Phase 1,3: ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜ë“¤\n",
    "# ============================================================\n",
    "\n",
    "def export_to_markdown(report_data: Dict[str, Any], output_path: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¦¬í¬íŠ¸ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (Phase 1)\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    # ì œëª©\n",
    "    lines.append(f\"# {report_data['title']}\\n\")\n",
    "    lines.append(f\"ìƒì„±ì¼ì‹œ: {report_data['generated_at'].strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    if report_data['metadata'].get('scenario_no'):\n",
    "        lines.append(f\"ì‹œë‚˜ë¦¬ì˜¤: {report_data['metadata']['scenario_no']}\\n\")\n",
    "\n",
    "    lines.append(\"\\n---\\n\\n\")\n",
    "\n",
    "    # ê° ì„¹ì…˜\n",
    "    sections = report_data.get('sections', {})\n",
    "\n",
    "    for section_name, section_data in sections.items():\n",
    "        lines.append(f\"## {section_data['title']}\\n\\n\")\n",
    "        lines.append(f\"{section_data.get('summary', '')}\\n\\n\")\n",
    "\n",
    "        # ë°ì´í„° í…Œì´ë¸”\n",
    "        if 'data' in section_data and section_data['data']:\n",
    "            data = section_data['data'][:20]\n",
    "            if data:\n",
    "                headers = list(data[0].keys())\n",
    "                lines.append(\"| \" + \" | \".join(headers) + \" |\\n\")\n",
    "                lines.append(\"| \" + \" | \".join(['---'] * len(headers)) + \" |\\n\")\n",
    "\n",
    "                for row in data:\n",
    "                    values = [str(row.get(h, '')) for h in headers]\n",
    "                    lines.append(\"| \" + \" | \".join(values) + \" |\\n\")\n",
    "\n",
    "                lines.append(\"\\n\")\n",
    "\n",
    "        lines.append(\"\\n\")\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_to_pdf(report_data: Dict[str, Any], output_path: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¦¬í¬íŠ¸ë¥¼ PDF í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (Phase 3)\n",
    "    \"\"\"\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.lib import colors\n",
    "    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "    from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
    "    from reportlab.lib.units import cm\n",
    "    import os\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "\n",
    "    doc = SimpleDocTemplate(output_path, pagesize=A4)\n",
    "    story = []\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Heading1'],\n",
    "        fontSize=24,\n",
    "        spaceAfter=30\n",
    "    )\n",
    "    heading_style = styles['Heading2']\n",
    "\n",
    "    story.append(Paragraph(report_data['title'], title_style))\n",
    "    story.append(Spacer(1, 0.5*cm))\n",
    "\n",
    "    meta_text = f\"ìƒì„±ì¼ì‹œ: {report_data['generated_at'].strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    if report_data['metadata'].get('scenario_no'):\n",
    "        meta_text += f\" | ì‹œë‚˜ë¦¬ì˜¤: {report_data['metadata']['scenario_no']}\"\n",
    "    story.append(Paragraph(meta_text, styles['Normal']))\n",
    "    story.append(Spacer(1, 1*cm))\n",
    "\n",
    "    sections = report_data.get('sections', {})\n",
    "\n",
    "    for section_name, section_data in sections.items():\n",
    "        story.append(Paragraph(section_data['title'], heading_style))\n",
    "        story.append(Spacer(1, 0.3*cm))\n",
    "\n",
    "        story.append(Paragraph(section_data.get('summary', ''), styles['Normal']))\n",
    "        story.append(Spacer(1, 0.5*cm))\n",
    "\n",
    "        if 'data' in section_data and section_data['data']:\n",
    "            data = section_data['data'][:10]\n",
    "            if data:\n",
    "                headers = list(data[0].keys())\n",
    "                table_data = [headers]\n",
    "\n",
    "                for row in data:\n",
    "                    table_data.append([str(row.get(h, '')) for h in headers])\n",
    "\n",
    "                t = Table(table_data)\n",
    "                t.setStyle(TableStyle([\n",
    "                    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                    ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "                    ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "                ]))\n",
    "\n",
    "                story.append(t)\n",
    "                story.append(Spacer(1, 0.5*cm))\n",
    "\n",
    "        story.append(Spacer(1, 0.5*cm))\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_to_excel(report_data: Dict[str, Any], output_path: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¦¬í¬íŠ¸ë¥¼ Excel í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (Phase 3)\n",
    "    \"\"\"\n",
    "    from openpyxl import Workbook\n",
    "    from openpyxl.styles import Font, Alignment, PatternFill\n",
    "    import os\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "\n",
    "    wb = Workbook()\n",
    "\n",
    "    if 'Sheet' in wb.sheetnames:\n",
    "        del wb['Sheet']\n",
    "\n",
    "    summary_ws = wb.create_sheet(title=\"ìš”ì•½\")\n",
    "    summary_ws.append([report_data['title']])\n",
    "    summary_ws.append([])\n",
    "    summary_ws.append(['ìƒì„±ì¼ì‹œ', report_data['generated_at'].strftime('%Y-%m-%d %H:%M:%S')])\n",
    "\n",
    "    if report_data['metadata'].get('scenario_no'):\n",
    "        summary_ws.append(['ì‹œë‚˜ë¦¬ì˜¤', report_data['metadata']['scenario_no']])\n",
    "\n",
    "    summary_ws.append([])\n",
    "    summary_ws.append(['ì„¹ì…˜', 'ìš”ì•½'])\n",
    "\n",
    "    title_font = Font(size=16, bold=True)\n",
    "    header_font = Font(bold=True)\n",
    "    header_fill = PatternFill(start_color='CCCCCC', end_color='CCCCCC', fill_type='solid')\n",
    "\n",
    "    summary_ws['A1'].font = title_font\n",
    "\n",
    "    sections = report_data.get('sections', {})\n",
    "\n",
    "    for section_name, section_data in sections.items():\n",
    "        summary_ws.append([section_data['title'], section_data.get('summary', '')])\n",
    "\n",
    "        ws = wb.create_sheet(title=section_data['title'][:30])\n",
    "\n",
    "        ws.append([section_data['title']])\n",
    "        ws.append([section_data.get('summary', '')])\n",
    "        ws.append([])\n",
    "\n",
    "        if 'data' in section_data and section_data['data']:\n",
    "            data = section_data['data']\n",
    "            if data:\n",
    "                headers = list(data[0].keys())\n",
    "                ws.append(headers)\n",
    "\n",
    "                for col_idx, _ in enumerate(headers, 1):\n",
    "                    cell = ws.cell(row=ws.max_row, column=col_idx)\n",
    "                    cell.font = header_font\n",
    "                    cell.fill = header_fill\n",
    "                    cell.alignment = Alignment(horizontal='center')\n",
    "\n",
    "                for row_data in data:\n",
    "                    ws.append([row_data.get(h, '') for h in headers])\n",
    "\n",
    "        for column in ws.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)\n",
    "            ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    wb.save(output_path)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_report(\n",
    "    report_data: Dict[str, Any],\n",
    "    format: str = 'pdf',\n",
    "    output_dir: str = './reports'\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    ë¦¬í¬íŠ¸ë¥¼ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° (Phase 3)\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    results = {}\n",
    "\n",
    "    if format in ['pdf', 'all']:\n",
    "        pdf_path = os.path.join(output_dir, f'ALM_Report_{timestamp}.pdf')\n",
    "        export_to_pdf(report_data, pdf_path)\n",
    "        results['pdf'] = pdf_path\n",
    "\n",
    "    if format in ['excel', 'all']:\n",
    "        excel_path = os.path.join(output_dir, f'ALM_Report_{timestamp}.xlsx')\n",
    "        export_to_excel(report_data, excel_path)\n",
    "        results['excel'] = excel_path\n",
    "\n",
    "    if format in ['markdown', 'all']:\n",
    "        md_path = os.path.join(output_dir, f'ALM_Report_{timestamp}.md')\n",
    "        export_to_markdown(report_data, md_path)\n",
    "        results['markdown'] = md_path\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"âœ“ Phase 1-3 ëª¨ë“  ë¦¬í¬íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì‹œê°í™” í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹œê°í™” í•¨ìˆ˜ ë¹„í™œì„±í™”ë¨ (TODO 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# DEPRECATED: ì‹œê°í™” ì œê±°ë¨ (TODO 4)\n",
    "# í•„ìš”ì‹œ ë‚˜ì¤‘ì— ì¬í™œì„±í™” ê°€ëŠ¥\n",
    "\n",
    "def visualize_query_result(query: str, chart_type: str = 'bar', \n",
    "                          x_col: Optional[str] = None, \n",
    "                          y_col: Optional[str] = None,\n",
    "                          title: Optional[str] = None) -> str:\n",
    "    \n",
    "    ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì‹œê°í™”\n",
    "    \n",
    "    Args:\n",
    "        query: SQL ì¿¼ë¦¬\n",
    "        chart_type: ì°¨íŠ¸ íƒ€ì… (bar, line, pie, scatter)\n",
    "        x_col: Xì¶• ì»¬ëŸ¼ëª…\n",
    "        y_col: Yì¶• ì»¬ëŸ¼ëª…\n",
    "        title: ì°¨íŠ¸ ì œëª©\n",
    "    \n",
    "    Returns:\n",
    "        ì‹œê°í™” ì™„ë£Œ ë©”ì‹œì§€\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if not result[\"success\"]:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "    \n",
    "    df = result[\"dataframe\"]\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # x, y ì»¬ëŸ¼ ìë™ ì„ íƒ\n",
    "    if x_col is None:\n",
    "        x_col = df.columns[0]\n",
    "    if y_col is None and len(df.columns) > 1:\n",
    "        y_col = df.columns[1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    if chart_type == 'bar':\n",
    "        plt.bar(df[x_col].astype(str), df[y_col])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    elif chart_type == 'line':\n",
    "        plt.plot(df[x_col], df[y_col], marker='o')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    elif chart_type == 'pie':\n",
    "        plt.pie(df[y_col], labels=df[x_col], autopct='%1.1f%%')\n",
    "    elif chart_type == 'scatter':\n",
    "        plt.scatter(df[x_col], df[y_col])\n",
    "    \n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col if y_col else '')\n",
    "    plt.title(title if title else f\"{y_col} by {x_col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # í…Œì´ë¸”ë„ í•¨ê»˜ ì¶œë ¥\n",
    "    print(\"\\në°ì´í„° í…Œì´ë¸”:\")\n",
    "    print(df.to_string())\n",
    "    \n",
    "    return f\"ì°¨íŠ¸ ìƒì„± ì™„ë£Œ! ({chart_type} ì°¨íŠ¸, {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸)\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"ì‹œê°í™” í•¨ìˆ˜ ë¹„í™œì„±í™”ë¨ (TODO 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangChain Tools ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1123100398.py, line 204)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 204\u001b[0;36m\u001b[0m\n\u001b[0;31m    StructuredTool.from_function(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic ëª¨ë¸ ì •ì˜ (ì…ë ¥ ìŠ¤í‚¤ë§ˆ)\n",
    "class SearchContractsInput(BaseModel):\n",
    "    filters_json: str = Field(default=\"\", description=\"JSON í˜•ì‹ì˜ í•„í„° ì¡°ê±´\")\n",
    "\n",
    "class LiquidityGapInput(BaseModel):\n",
    "    scenario_no: str = Field(default=\"\", description=\"ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸\")\n",
    "\n",
    "class ExchangeRateInput(BaseModel):\n",
    "    currency_and_date: str = Field(description=\"í†µí™”ì½”ë“œ ë˜ëŠ” 'í†µí™”ì½”ë“œ,ë‚ ì§œ'\")\n",
    "\n",
    "class InterestRateInput(BaseModel):\n",
    "    rate_info: str = Field(description=\"ê¸ˆë¦¬ì½”ë“œ ë˜ëŠ” 'ê¸ˆë¦¬ì½”ë“œ,ê¸°ê°„'\")\n",
    "\n",
    "class AggregateStatsInput(BaseModel):\n",
    "    params: str = Field(description=\"'í…Œì´ë¸”ëª…,ê·¸ë£¹ì»¬ëŸ¼,ì§‘ê³„ì»¬ëŸ¼'\")\n",
    "\n",
    "# TODO 4: VisualizeInput ë° _visualize_data ì œê±°ë¨\n",
    "\n",
    "\n",
    "# Phase 2: ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ ë° ì¶”ì„¸ ë¶„ì„\n",
    "class CompareScenariosInput(BaseModel):\n",
    "    scenario_list: str = Field(description=\"ë¹„êµí•  ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ë“¤ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: '1,2,3')\")\n",
    "    comparison_metrics: str = Field(default=\"\", description=\"ë¹„êµí•  ì§€í‘œ (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "class AnalyzeTrendsInput(BaseModel):\n",
    "    metric_type: str = Field(description=\"'exchange_rate' ë˜ëŠ” 'interest_rate'\")\n",
    "    currency_or_rate_cd: str = Field(default=\"\", description=\"í†µí™” ì½”ë“œ ë˜ëŠ” ê¸ˆë¦¬ ì½”ë“œ (ì„ íƒì‚¬í•­)\")\n",
    "    start_date: str = Field(default=\"\", description=\"ì‹œì‘ ë‚ ì§œ YYYY-MM-DD (ì„ íƒì‚¬í•­)\")\n",
    "    end_date: str = Field(default=\"\", description=\"ì¢…ë£Œ ë‚ ì§œ YYYY-MM-DD (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "# Phase 1/3: ë¦¬í¬íŠ¸ ìƒì„± ë° ë‚´ë³´ë‚´ê¸°\n",
    "class GenerateReportInput(BaseModel):\n",
    "    include_sections: str = Field(default=\"\", description=\"í¬í•¨í•  ì„¹ì…˜ (ì‰¼í‘œ êµ¬ë¶„, ì„ íƒì‚¬í•­)\")\n",
    "    scenario_no: str = Field(default=\"\", description=\"ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)\")\n",
    "\n",
    "class ExportReportInput(BaseModel):\n",
    "    format: str = Field(default=\"pdf\", description=\"'pdf', 'excel', 'markdown', 'all' ì¤‘ í•˜ë‚˜\")\n",
    "    output_dir: str = Field(default=\"./reports\", description=\"ì €ì¥ ë””ë ‰í† ë¦¬\")\n",
    "\n",
    "\n",
    "\n",
    "# ë„êµ¬ í•¨ìˆ˜ë“¤\n",
    "\n",
    "def _compare_scenarios(scenario_list: str, comparison_metrics: str = \"\") -> str:\n",
    "    \"\"\"ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    scenarios = [int(s.strip()) for s in scenario_list.split(',')]\n",
    "    metrics = None\n",
    "    if comparison_metrics:\n",
    "        metrics = [m.strip() for m in comparison_metrics.split(',')]\n",
    "\n",
    "    result = compare_scenarios(scenarios, metrics)\n",
    "\n",
    "    output = f\"âœ“ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ ì™„ë£Œ\\n\\n{result['summary']}\\n\\n\"\n",
    "\n",
    "    for scenario_no in scenarios:\n",
    "        key = f'scenario_{scenario_no}'\n",
    "        if key in result['comparison_data']:\n",
    "            output += f\"\\n--- ì‹œë‚˜ë¦¬ì˜¤ {scenario_no} ìƒì„¸ ---\\n\"\n",
    "            data = result['comparison_data'][key]['data'][:5]\n",
    "            for row in data:\n",
    "                output += f\"{row}\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "def _analyze_trends(metric_type: str, currency_or_rate_cd: str = \"\",\n",
    "                   start_date: str = \"\", end_date: str = \"\") -> str:\n",
    "    \"\"\"ì‹œê³„ì—´ ì¶”ì„¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    result = analyze_trends(\n",
    "        metric_type=metric_type,\n",
    "        currency_or_rate_cd=currency_or_rate_cd if currency_or_rate_cd else None,\n",
    "        start_date=start_date if start_date else None,\n",
    "        end_date=end_date if end_date else None\n",
    "    )\n",
    "\n",
    "    if 'error' in result:\n",
    "        return f\"ì˜¤ë¥˜: {result['error']}\"\n",
    "\n",
    "    stats = result['statistics']\n",
    "    output = f\"âœ“ ì¶”ì„¸ ë¶„ì„ ì™„ë£Œ ({result['metric_type']})\\n\\n\"\n",
    "    output += f\"ì¶”ì„¸: {result['trend']}\\n\\n\"\n",
    "    output += f\"í†µê³„:\\n\"\n",
    "    output += f\"  - ë°ì´í„° í¬ì¸íŠ¸: {stats['count']}ê°œ\\n\"\n",
    "    output += f\"  - í‰ê· : {stats['mean']:.4f}\\n\"\n",
    "    output += f\"  - í‘œì¤€í¸ì°¨: {stats['std']:.4f}\\n\"\n",
    "    output += f\"  - ë²”ìœ„: {stats['min']:.4f} ~ {stats['max']:.4f}\\n\"\n",
    "    output += f\"  - ë³€í™”: {stats['first_value']:.4f} â†’ {stats['last_value']:.4f} ({stats['change_pct']:.2f}%)\\n\"\n",
    "\n",
    "    if 'slope' in stats:\n",
    "        output += f\"  - ê¸°ìš¸ê¸°: {stats['slope']:.6f}\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ë¡œ ë§ˆì§€ë§‰ ë¦¬í¬íŠ¸ ì €ì¥\n",
    "_last_report = None\n",
    "\n",
    "def _generate_report(include_sections: str = \"\", scenario_no: str = \"\") -> str:\n",
    "    \"\"\"ì¢…í•© ALM ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    global _last_report\n",
    "\n",
    "    sections = None\n",
    "    if include_sections:\n",
    "        sections = [s.strip() for s in include_sections.split(',')]\n",
    "\n",
    "    scenario = None\n",
    "    if scenario_no:\n",
    "        scenario = int(scenario_no)\n",
    "\n",
    "    _last_report = generate_comprehensive_report(sections, scenario)\n",
    "\n",
    "    output = f\"âœ“ {_last_report['title']} ìƒì„± ì™„ë£Œ\\n\\n\"\n",
    "    output += f\"ìƒì„±ì¼ì‹œ: {_last_report['generated_at'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "    output += f\"ì„¹ì…˜ ìˆ˜: {len(_last_report['sections'])}ê°œ\\n\\n\"\n",
    "\n",
    "    for section_name, section_data in _last_report['sections'].items():\n",
    "        output += f\"- {section_data['title']}: {section_data.get('summary', '')}\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "def _export_report(format: str = \"pdf\", output_dir: str = \"./reports\") -> str:\n",
    "    \"\"\"ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ ì§€ì • í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤.\"\"\"\n",
    "    global _last_report\n",
    "\n",
    "    if _last_report is None:\n",
    "        return \"ì˜¤ë¥˜: ë¨¼ì € ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš” (generate_comprehensive_report ë„êµ¬ ì‚¬ìš©)\"\n",
    "\n",
    "    results = export_report(_last_report, format, output_dir)\n",
    "\n",
    "    output = f\"âœ“ ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ\\n\\n\"\n",
    "    for fmt, path in results.items():\n",
    "        output += f\"- {fmt.upper()}: {path}\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def _search_alm_contracts(filters_json: str = \"\") -> str:\n",
    "    \"\"\"ALM ê³„ì•½ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    filters = json.loads(filters_json) if filters_json else None\n",
    "    return search_alm_contracts(filters)\n",
    "\n",
    "def _analyze_liquidity_gap(scenario_no: str = \"\") -> str:\n",
    "    \"\"\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    scenario = int(scenario_no) if scenario_no else None\n",
    "    return analyze_liquidity_gap(scenario)\n",
    "\n",
    "def _get_exchange_rate(currency_and_date: str) -> str:\n",
    "    \"\"\"í™˜ìœ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = currency_and_date.split(',')\n",
    "    currency = parts[0].strip()\n",
    "    date = parts[1].strip() if len(parts) > 1 else None\n",
    "    return get_exchange_rate(currency, date)\n",
    "\n",
    "def _get_interest_rate(rate_info: str) -> str:\n",
    "    \"\"\"ê¸ˆë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = rate_info.split(',')\n",
    "    rate_cd = int(parts[0].strip())\n",
    "    term = int(parts[1].strip()) if len(parts) > 1 else None\n",
    "    return get_interest_rate(rate_cd, term)\n",
    "\n",
    "def _get_aggregate_stats(params: str) -> str:\n",
    "    \"\"\"í…Œì´ë¸”ì˜ ì§‘ê³„ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = params.split(',')\n",
    "    if len(parts) != 3:\n",
    "        return \"ì˜¤ë¥˜: ì •í™•íˆ 3ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤\"\n",
    "    return get_aggregate_stats(parts[0].strip(), parts[1].strip(), parts[2].strip())\n",
    "\n",
    "# StructuredToolë¡œ ë„êµ¬ ìƒì„± (visualize_data ì œê±°ë¨)\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        func=_search_alm_contracts,\n",
    "        name=\"search_alm_contracts\",\n",
    "        description=\"ALM ê³„ì•½ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. filters_json: JSON í˜•ì‹ì˜ í•„í„° ì¡°ê±´ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´\",\n",
    "        args_schema=SearchContractsInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_analyze_liquidity_gap,\n",
    "        name=\"analyze_liquidity_gap\",\n",
    "        description=\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•©ë‹ˆë‹¤. scenario_no: ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)\",\n",
    "        args_schema=LiquidityGapInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_exchange_rate,\n",
    "        name=\"get_exchange_rate\",\n",
    "        description=\"í™˜ìœ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. currency_and_date: í†µí™”ì½”ë“œ ë˜ëŠ” 'í†µí™”ì½”ë“œ,ë‚ ì§œ'\",\n",
    "        args_schema=ExchangeRateInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_interest_rate,\n",
    "        name=\"get_interest_rate\",\n",
    "        description=\"ê¸ˆë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. rate_info: ê¸ˆë¦¬ì½”ë“œ ë˜ëŠ” 'ê¸ˆë¦¬ì½”ë“œ,ê¸°ê°„'\",\n",
    "        args_schema=InterestRateInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_aggregate_stats,\n",
    "        name=\"get_aggregate_stats\",\n",
    "        description=\"í…Œì´ë¸”ì˜ ì§‘ê³„ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. params: 'í…Œì´ë¸”ëª…,ê·¸ë£¹ì»¬ëŸ¼,ì§‘ê³„ì»¬ëŸ¼'\",\n",
    "        args_schema=AggregateStatsInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_compare_scenarios,\n",
    "        name=\"compare_scenarios\",\n",
    "        description=\"ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì˜ ìœ ë™ì„± ê°­ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤\",\n",
    "        args_schema=CompareScenariosInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_analyze_trends,\n",
    "        name=\"analyze_trends\",\n",
    "        description=\"í™˜ìœ¨ ë˜ëŠ” ê¸ˆë¦¬ì˜ ì‹œê³„ì—´ ì¶”ì„¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤\",\n",
    "        args_schema=AnalyzeTrendsInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_generate_report,\n",
    "        name=\"generate_comprehensive_report\",\n",
    "        description=\"ALM ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\",\n",
    "        args_schema=GenerateReportInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_export_report,\n",
    "        name=\"export_report\",\n",
    "        description=\"ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ PDF/Excel/Markdown í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤\",\n",
    "        args_schema=ExportReportInput\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"âœ“ ì´ {len(tools)}ê°œì˜ ë„êµ¬ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤ (Phase 1-3 ì™„ë£Œ)\")\n",
    "for tool_item in tools:\n",
    "    print(f\"  - {tool_item.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Agent ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. ALMAgent í´ë˜ìŠ¤ ì •ì˜ (TODO 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALMAgent í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "class ALMAgent:\n",
    "    \"\"\"\n",
    "    ALM ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ReAct íŒ¨í„´ ì—ì´ì „íŠ¸\n",
    "    \n",
    "    ê¸°ëŠ¥:\n",
    "    - ë°˜ë³µì  ë„êµ¬ í˜¸ì¶œ ë° ì¶”ë¡  (TODO 1)\n",
    "    - ëŒ€í™” ì´ë ¥ ê´€ë¦¬\n",
    "    - ì‹¤í–‰ ë¡œê¹… ë° ë””ë²„ê¹…\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            llm: LLM ì¸ìŠ¤í„´ìŠ¤\n",
    "            tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.verbose = verbose\n",
    "        self.max_iterations = 10\n",
    "    \n",
    "    def _log(self, message: str):\n",
    "        \"\"\"verbose ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥\"\"\"\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "    \n",
    "    def run(self, user_input: str, chat_history: list = None) -> str:\n",
    "        \"\"\"\n",
    "        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (TODO 1: ë°˜ë³µì  ReAct ë£¨í”„)\n",
    "        \n",
    "        Args:\n",
    "            user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "            chat_history: ëŒ€í™” ì´ë ¥\n",
    "        \n",
    "        Returns:\n",
    "            ìµœì¢… ì‘ë‹µ\n",
    "        \"\"\"\n",
    "        if chat_history is None:\n",
    "            chat_history = []\n",
    "        \n",
    "        # ë©”ì‹œì§€ êµ¬ì„± (TODO 2: ë¶„ë¦¬ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)\n",
    "        system_message = SystemMessage(content=SYSTEM_PROMPT)\n",
    "        \n",
    "        # ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "        enhanced_prompt = f\"\"\"{user_input}\n",
    "\n",
    "ë¶„ì„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:\n",
    "1. í•„ìš”í•œ ì •ë³´ íŒŒì•…\n",
    "2. ì ì ˆí•œ ë„êµ¬ë¡œ ë°ì´í„° ì¡°íšŒ\n",
    "3. ì¶”ê°€ ì •ë³´ í•„ìš”ì‹œ ë‹¤ë¥¸ ë„êµ¬ ì‚¬ìš©\n",
    "4. ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€\"\"\"\n",
    "        \n",
    "        messages = [system_message]\n",
    "        messages.extend(chat_history)\n",
    "        messages.append(HumanMessage(content=enhanced_prompt))\n",
    "        \n",
    "        # ReAct ë°˜ë³µ ë£¨í”„ (TODO 1)\n",
    "        iteration = 0\n",
    "        tool_log = []\n",
    "        \n",
    "        while iteration < self.max_iterations:\n",
    "            iteration += 1\n",
    "            self._log(f\"\\n{'='*60}\")\n",
    "            self._log(f\"ğŸ”„ Iteration {iteration}\")\n",
    "            self._log(f\"{'='*60}\")\n",
    "            \n",
    "            # LLM ì¶”ë¡ \n",
    "            response = self.llm_with_tools.invoke(messages)\n",
    "            \n",
    "            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "            if not hasattr(response, 'tool_calls') or not response.tool_calls:\n",
    "                self._log(\"âœ“ ë¶„ì„ ì™„ë£Œ\")\n",
    "                return self._format_response(response.content, tool_log)\n",
    "            \n",
    "            # ë„êµ¬ ì‹¤í–‰ (í•œ ë²ˆì— í•˜ë‚˜ì”© - TODO 1ì˜ í•µì‹¬)\n",
    "            tool_call = response.tool_calls[0]\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            \n",
    "            self._log(f\"ğŸ”§ ë„êµ¬: {tool_name}\")\n",
    "            self._log(f\"ğŸ“ ì¸ì: {tool_args}\")\n",
    "            \n",
    "            # ë„êµ¬ ì‹¤í–‰\n",
    "            observation = self._execute_tool(tool_name, tool_args)\n",
    "            \n",
    "            # ë¡œê·¸ ê¸°ë¡\n",
    "            tool_log.append({\n",
    "                'iteration': iteration,\n",
    "                'tool': tool_name,\n",
    "                'success': not observation.startswith('ì˜¤ë¥˜')\n",
    "            })\n",
    "            \n",
    "            self._log(f\"ğŸ“Š ê²°ê³¼: {observation[:100]}...\")\n",
    "            \n",
    "            # ê´€ì°° ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‹¤ìŒ ë°˜ë³µì—ì„œ LLMì´ ì´ ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ìŒ í–‰ë™ ê²°ì •)\n",
    "            messages.append(HumanMessage(\n",
    "                content=f\"[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ - Iteration {iteration}]\\n\"\n",
    "                       f\"ë„êµ¬: {tool_name}\\n\"\n",
    "                       f\"ê²°ê³¼:\\n{observation}\\n\\n\"\n",
    "                       f\"ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ì„¸ìš”.\"\n",
    "            ))\n",
    "        \n",
    "        return \"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    def _execute_tool(self, tool_name: str, tool_args: dict) -> str:\n",
    "        \"\"\"ë„êµ¬ ì‹¤í–‰\"\"\"\n",
    "        tool = self.tools.get(tool_name)\n",
    "        \n",
    "        if not tool:\n",
    "            return f\"ì˜¤ë¥˜: '{tool_name}' ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        try:\n",
    "            return tool.invoke(tool_args)\n",
    "        except Exception as e:\n",
    "            return f\"ì˜¤ë¥˜: {tool_name} ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {str(e)}\"\n",
    "    \n",
    "    def _format_response(self, content: str, tool_log: list) -> str:\n",
    "        \"\"\"ìµœì¢… ì‘ë‹µ í¬ë§·íŒ…\"\"\"\n",
    "        if not self.verbose or not tool_log:\n",
    "            return content\n",
    "        \n",
    "        summary = f\"\\n\\n{'='*60}\\nğŸ“‹ ì‹¤í–‰ ìš”ì•½\\n{'='*60}\\n\"\n",
    "        summary += f\"ì´ {len(tool_log)}ê°œ ë„êµ¬ ì‹¤í–‰\\n\"\n",
    "        \n",
    "        for log in tool_log:\n",
    "            status = \"âœ“\" if log['success'] else \"âœ—\"\n",
    "            summary += f\"  {status} [{log['iteration']}] {log['tool']}\\n\"\n",
    "        \n",
    "        return content + summary\n",
    "\n",
    "print(\"ALMAgent í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Agent ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ALM Agent ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "  - ë„êµ¬: 5ê°œ\n",
      "  - ìµœëŒ€ ë°˜ë³µ: 10íšŒ\n"
     ]
    }
   ],
   "source": [
    "# Agent ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (TODO 3)\n",
    "alm_agent = ALMAgent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ ALM Agent ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "print(f\"  - ë„êµ¬: {len(tools)}ê°œ\")\n",
    "print(f\"  - ìµœëŒ€ ë°˜ë³µ: {alm_agent.max_iterations}íšŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (TODO 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì—­í• , ê¸°ëŠ¥, ì§€ì¹¨ ì •ì˜\n",
    "SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ ALM(ìì‚°ë¶€ì±„ê´€ë¦¬) ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\n",
    "1. ALM_INST - ALM ê³„ì•½ ì •ë³´ (í†µí™”, ì”ì•¡, ê¸ˆë¦¬, ë§Œê¸°ì¼ ë“±)\n",
    "2. NFAR_LIQ_GAP_310524 - ìœ ë™ì„± ê°­ ë¶„ì„ (ì›ê¸ˆê°­, ì´ìê°­, ê¸°ê°„ëŒ€ë³„)\n",
    "3. NFAT_LIQ_INDEX_SUMMARY_M - ìœ ë™ì„± ì§€ìˆ˜ ìš”ì•½\n",
    "4. NFA_EXCH_RATE_HIST - í™˜ìœ¨ ì´ë ¥\n",
    "5. NFA_IRC_RATE_HIST - ê¸ˆë¦¬ ì´ë ¥\n",
    "6. orders_summary - ì£¼ë¬¸ ìš”ì•½\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "1. search_alm_contracts - ALM ê³„ì•½ ê²€ìƒ‰\n",
    "2. analyze_liquidity_gap - ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "3. get_exchange_rate - í™˜ìœ¨ ì •ë³´ ì¡°íšŒ\n",
    "4. get_interest_rate - ê¸ˆë¦¬ ì •ë³´ ì¡°íšŒ\n",
    "5. get_aggregate_stats - í…Œì´ë¸” ì§‘ê³„ í†µê³„\n",
    "6. generate_comprehensive_report - ALM ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "7. compare_scenarios - ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ ë¶„ì„\n",
    "8. analyze_trends - ì‹œê³„ì—´ ì¶”ì„¸ ë¶„ì„ (í™˜ìœ¨, ê¸ˆë¦¬)\n",
    "9. export_report - ë¦¬í¬íŠ¸ë¥¼ PDF/Excel/Markdownìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\n",
    "\n",
    "ì‘ì—… ì§€ì¹¨:\n",
    "- ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”\n",
    "- í•„ìš”í•œ ê²½ìš° ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "- ê²°ê³¼ëŠ” í…Œì´ë¸”ê³¼ ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”\n",
    "- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”\n",
    "\n",
    "ë¦¬í¬íŠ¸ ìƒì„± ì‹œ:\n",
    "- ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸: generate_comprehensive_report ë„êµ¬ ì‚¬ìš©\n",
    "- ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ: compare_scenarios ë„êµ¬ ì‚¬ìš©\n",
    "- ì¶”ì„¸ ë¶„ì„: analyze_trends ë„êµ¬ ì‚¬ìš©\n",
    "- ë‚´ë³´ë‚´ê¸°: export_report ë„êµ¬ë¡œ PDF/Excel/Markdown ìƒì„±\n",
    "- ë¦¬í¬íŠ¸ëŠ” ìë™ìœ¼ë¡œ ./reports ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ìœ ì € í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ - ë™ì  ì§ˆë¬¸ ë‚´ìš©\n",
    "USER_PROMPT_TEMPLATE = \"\"\"{user_question}\n",
    "\n",
    "ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# LLMì— ë„êµ¬ ë°”ì¸ë”© (ìµœì‹  ë°©ì‹)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ê°„ë‹¨í•œ ì±„íŒ… í•¨ìˆ˜ (Agent ì—†ì´ ì§ì ‘ êµ¬í˜„)\n",
    "def run_agent(user_input: str, chat_history: list = None) -> str:\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  í•„ìš”ì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œ\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        chat_history: ëŒ€í™” ì´ë ¥\n",
    "    \n",
    "    Returns:\n",
    "        ì‘ë‹µ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    system_message = \"\"\"ë‹¹ì‹ ì€ ALM(ìì‚°ë¶€ì±„ê´€ë¦¬) ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\n",
    "1. ALM_INST - ALM ê³„ì•½ ì •ë³´ (í†µí™”, ì”ì•¡, ê¸ˆë¦¬, ë§Œê¸°ì¼ ë“±)\n",
    "2. NFAR_LIQ_GAP_310524 - ìœ ë™ì„± ê°­ ë¶„ì„ (ì›ê¸ˆê°­, ì´ìê°­, ê¸°ê°„ëŒ€ë³„)\n",
    "3. NFAT_LIQ_INDEX_SUMMARY_M - ìœ ë™ì„± ì§€ìˆ˜ ìš”ì•½\n",
    "4. NFA_EXCH_RATE_HIST - í™˜ìœ¨ ì´ë ¥\n",
    "5. NFA_IRC_RATE_HIST - ê¸ˆë¦¬ ì´ë ¥\n",
    "6. orders_summary - ì£¼ë¬¸ ìš”ì•½\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "ê²°ê³¼ëŠ” í…Œì´ë¸”, ê·¸ë˜í”„, ê·¸ë¦¬ê³  ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\n",
    "\n",
    "í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "    # ë©”ì‹œì§€ êµ¬ì„±\n",
    "    messages = [SystemMessage(content=system_message)]\n",
    "    messages.extend(chat_history)\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    \n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Tool calls í™•ì¸\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        # ë„êµ¬ ì‹¤í–‰\n",
    "        tool_results = []\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            \n",
    "            # í•´ë‹¹ ë„êµ¬ ì°¾ê¸°\n",
    "            tool_func = None\n",
    "            for t in tools:\n",
    "                if t.name == tool_name:\n",
    "                    tool_func = t\n",
    "                    break\n",
    "            \n",
    "            if tool_func:\n",
    "                try:\n",
    "                    # ë„êµ¬ ì‹¤í–‰\n",
    "                    result = tool_func.invoke(tool_args)\n",
    "                    tool_results.append(f\"\\n[{tool_name} ì‹¤í–‰ ê²°ê³¼]\\n{result}\")\n",
    "                except Exception as e:\n",
    "                    tool_results.append(f\"\\n[{tool_name} ì˜¤ë¥˜]\\n{str(e)}\")\n",
    "        \n",
    "        # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        if tool_results:\n",
    "            final_prompt = f\"{user_input}\\n\\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:{''.join(tool_results)}\\n\\nìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "            messages_final = [SystemMessage(content=system_message)]\n",
    "            messages_final.append(HumanMessage(content=final_prompt))\n",
    "            final_response = llm.invoke(messages_final)\n",
    "            return final_response.content\n",
    "    \n",
    "    # Tool callì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì‘ë‹µ ë°˜í™˜\n",
    "    return response.content\n",
    "\n",
    "print(\"Agent ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\n",
      "\n",
      "ì‚¬ìš© ì˜ˆì‹œ:\n",
      "  chat('ALM ê³„ì•½ ì¤‘ KRW í†µí™” ê³„ì•½ì„ ë³´ì—¬ì¤˜')\n",
      "  chat('ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì¤˜')\n",
      "  chat('USD í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜')\n",
      "  chat('í†µí™”ë³„ ì”ì•¡ì„ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜')\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í™” ì´ë ¥ ì €ì¥\n",
    "chat_history = []\n",
    "\n",
    "def chat(user_input: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì±—ë´‡ ì‘ë‹µ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    \"\"\"\n",
    "    global chat_history\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ì‚¬ìš©ì: {user_input}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Agent ì‹¤í–‰\n",
    "        response = run_agent(user_input, chat_history)\n",
    "        \n",
    "        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        chat_history.append(AIMessage(content=response))\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ì±—ë´‡: {response}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"\\nì‚¬ìš© ì˜ˆì‹œ:\")\n",
    "print(\"  chat('ALM ê³„ì•½ ì¤‘ KRW í†µí™” ê³„ì•½ì„ ë³´ì—¬ì¤˜')\")\n",
    "print(\"  chat('ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì¤˜')\")\n",
    "print(\"  chat('USD í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜')\")\n",
    "print(\"  chat('í†µí™”ë³„ ì”ì•¡ì„ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í…ŒìŠ¤íŠ¸ - ì˜ˆì œ ì§ˆì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ì‚¬ìš©ì: ALM_INST í…Œì´ë¸”ì—ì„œ ì²˜ìŒ 5ê°œ ê³„ì•½ì„ ë³´ì—¬ì¤˜\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ì±—ë´‡: ì£„ì†¡í•©ë‹ˆë‹¤! ì œê°€ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼°ë„¤ìš”. `ALM_INST` í…Œì´ë¸”ì—ì„œ ì²˜ìŒ 5ê°œì˜ ê³„ì•½ì„ ë³´ì—¬ë“œë¦¬ë ¤ê³  í–ˆëŠ”ë°, ì¿¼ë¦¬ ë¬¸ë²•ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì˜¬ë°”ë¥¸ ì¿¼ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "```sql\n",
      "SELECT * FROM ALM_INST LIMIT 5;\n",
      "```\n",
      "\n",
      "ì´ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ë©´ `ALM_INST` í…Œì´ë¸”ì˜ ì²˜ìŒ 5ê°œ ê³„ì•½ ì •ë³´(í†µí™”, ì”ì•¡, ê¸ˆë¦¬, ë§Œê¸°ì¼ ë“±)ë¥¼ ë³´ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ë°”ë¡œ ì‹¤í–‰í•´ ë“œë¦´ê²Œìš”.\n",
      "\n",
      "(â€» í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.)\n",
      "\n",
      "ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„, í•„ìš”í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ë‹¤ì‹œ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì œ 1: ALM ê³„ì•½ ê²€ìƒ‰\n",
    "chat(\"ALM_INST í…Œì´ë¸”ì—ì„œ ì²˜ìŒ 5ê°œ ê³„ì•½ì„ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ì‚¬ìš©ì: ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì„œ ë³´ì—¬ì¤˜\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ì±—ë´‡: ë¬¼ë¡ ì…ë‹ˆë‹¤! ì•„ë˜ëŠ” ìœ ë™ì„± ê°­ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…**ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Š ìœ ë™ì„± ê°­ ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
      "\n",
      "ìœ ë™ì„± ê°­ ë¶„ì„ì€ ê¸°ì—…ì´ë‚˜ ê¸ˆìœµê¸°ê´€ì´ **ë¯¸ë˜ì— ì–¼ë§ˆë‚˜ ë§ì€ ìê¸ˆì´ ë“¤ì–´ì˜¤ê³  ë‚˜ê°€ëŠ”ì§€**ë¥¼ ì‹œê¸°ë³„ë¡œ ë¹„êµí•˜ì—¬, ìœ ë™ì„± ë¦¬ìŠ¤í¬(ìê¸ˆ ë¶€ì¡± ìœ„í—˜)ë¥¼ í‰ê°€í•˜ëŠ” ì¤‘ìš”í•œ ë„êµ¬ì…ë‹ˆë‹¤.  \n",
      "ì´ ë¶„ì„ì€ **ì›ê¸ˆ ê°­**(ìì‚°ê³¼ ë¶€ì±„ì˜ ì›ê¸ˆ ì°¨ì´)ê³¼ **ì´ì ê°­**(ì´ì ìˆ˜ì…ê³¼ ì§€ì¶œì˜ ì°¨ì´)ì„ ê¸°ê°„ë³„ë¡œ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” ì£¼ìš” ê²°ê³¼ ìš”ì•½\n",
      "\n",
      "| ê¸°ê°„ëŒ€ (TIME_BAND) | ì´ ì›ê¸ˆê°­ | ì´ ì´ìê°­ | ê±´ìˆ˜ |\n",
      "|---------------------|-----------|-----------|------|\n",
      "| 1ë…„ ì´ë‚´            | 924ì¡°ì› | 2.2ì¡°ì› | 1,320ê±´ |\n",
      "| 2ë…„ ì´ë‚´            | 30ì¡°ì› | 2.5ì¡°ì› | 660ê±´ |\n",
      "| 3ë…„ ì´ë‚´            | 650ì¡°ì› | 10.8ì¡°ì› | 1,320ê±´ |\n",
      "| 4ë…„ ì´ë‚´            | 635ì¡°ì› | 8.5ì¡°ì› | 1,320ê±´ |\n",
      "| 5ë…„ ì´ë‚´            | 24ì¡°ì› | 5.1ì¡°ì› | 1,320ê±´ |\n",
      "| 6ë…„ ì´ë‚´            | 33ì¡°ì› | 2.6ì¡°ì› | 660ê±´ |\n",
      "| 7ë…„ ì´ë‚´            | 26ì¡°ì› | 3.0ì¡°ì› | 1,980ê±´ |\n",
      "| 8ë…„ ì´ë‚´            | 15ì¡°ì› | 1.7ì¡°ì› | 660ê±´ |\n",
      "| 9ë…„ ì´ë‚´            | 17ì¡°ì› | 1.7ì¡°ì› | 660ê±´ |\n",
      "| 10ë…„ ì´ë‚´           | 17ì¡°ì› | 1.6ì¡°ì› | 1,320ê±´ |\n",
      "| 11ë…„ ì´ë‚´           | 11ì¡°ì› | 1.5ì¡°ì› | 660ê±´ |\n",
      "| 12ë…„ ì´ë‚´           | 52ì¡°ì› | 2.8ì¡°ì› | 660ê±´ |\n",
      "| 15ë…„ ì´ìƒ           | 0ì› | 0ì› | 660ê±´ |\n",
      "| 18ë…„ ì´ìƒ           | 1,527ì¡°ì› | 100ì¡°ì› | 660ê±´ |\n",
      "| 20ë…„ ì´ìƒ           | 0ì› | 0ì› | 660ê±´ |\n",
      "| 24ë…„ ì´ìƒ           | 44ì¡°ì› | 4.1ì¡°ì› | 660ê±´ |\n",
      "| 99ë…„ ì´ìƒ (ì˜êµ¬)     | 28ì¡°ì› | 1.9ì¡°ì› | 660ê±´ |\n",
      "\n",
      "> âœ… **ì´ 17ê°œì˜ ê¸°ê°„ëŒ€**ë¡œ ë¶„ì„ë˜ì—ˆìœ¼ë©°, ê° ê¸°ê°„ëŒ€ë³„ë¡œ **ì›ê¸ˆê³¼ ì´ì ê°­**ì´ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” ì£¼ìš” ê´€ì°° í¬ì¸íŠ¸\n",
      "\n",
      "1. **ë‹¨ê¸° ìœ ë™ì„± ë¦¬ìŠ¤í¬ (1~5ë…„)**\n",
      "   - **1ë…„ ì´ë‚´**ì— ê°€ì¥ í° **ì›ê¸ˆê°­**(924ì¡°ì›)ì´ ë°œìƒí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ê¸°ë¡œ ë§Œê¸°ë˜ëŠ” ë¶€ì±„ê°€ ë§ì•„ **ìê¸ˆ ì¡°ë‹¬ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "   - **ì´ì ê°­**ë„ 2.2ì¡°ì›ìœ¼ë¡œ, ì´ì ì§€ì¶œì´ ìˆ˜ì…ë³´ë‹¤ ë§ì•„ **ë‹¨ê¸° ì´ìë¹„ìš© ë¶€ë‹´ì´ í¼**.\n",
      "\n",
      "2. **ì¤‘ì¥ê¸° ìœ ë™ì„± ë¦¬ìŠ¤í¬ (6ë…„ ì´ìƒ)**\n",
      "   - 18ë…„ ì´ìƒ ê¸°ê°„ëŒ€ì—ì„œëŠ” **ì›ê¸ˆê°­ì´ 1,527ì¡°ì›**ìœ¼ë¡œ ë§¤ìš° í° ìˆ˜ì¹˜ì…ë‹ˆë‹¤. ì´ëŠ” ì¥ê¸° ì±„ë¬´ì˜ ìƒí™˜ ë¶€ë‹´ì´ í´ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n",
      "   - ê·¸ëŸ¬ë‚˜ ì´ ê¸°ê°„ëŒ€ì˜ **ì´ì ê°­ì€ 100ì¡°ì›**ìœ¼ë¡œ, ì´ì ì§€ì¶œì´ ìƒë‹¹íˆ ë†’ì•„ **ì¥ê¸° ì±„ë¬´ì˜ ì´ì ë¶€ë‹´ë„ í¬ë©°**, ìœ ë™ì„± ë¦¬ìŠ¤í¬ê°€ ì§€ì†ë  ìˆ˜ ìˆìŒ.\n",
      "\n",
      "3. **íŠ¹ì´í•œ ê¸°ê°„ëŒ€**\n",
      "   - **15ë…„ ì´ìƒ**ê³¼ **20ë…„ ì´ìƒ**ì€ ì›ê¸ˆê°­ê³¼ ì´ìê°­ì´ ëª¨ë‘ 0ì›ì…ë‹ˆë‹¤. ì´ëŠ” ì´ ê¸°ê°„ëŒ€ì— ë§Œê¸°ë˜ëŠ” ê³„ì•½ì´ ì—†ê±°ë‚˜, ì´ë¯¸ ìƒí™˜ëœ ê³„ì•½ì´ í¬í•¨ë˜ì–´ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "   - **99ë…„ ì´ìƒ**(ì˜êµ¬ì±„ ë“±)ì€ 28ì¡°ì›ì˜ ì›ê¸ˆê°­ê³¼ 1.9ì¡°ì›ì˜ ì´ìê°­ì´ ìˆìœ¼ë¯€ë¡œ, **ì˜êµ¬ì ì¸ ìê¸ˆ ë¶€ë‹´ì´ ì¡´ì¬**í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê±´ìˆ˜ ë¶„í¬**\n",
      "   - 7ë…„ ì´ë‚´ì˜ ê±´ìˆ˜ê°€ 1,980ê±´ìœ¼ë¡œ ê°€ì¥ ë§ìœ¼ë©°, ì´ëŠ” **ì¤‘ì¥ê¸° ê³„ì•½ì˜ ì§‘ì¤‘ë„ê°€ ë†’ìŒ**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“ˆ ì‹œê°ì  ìš”ì•½ (ìš”ì•½ ê·¸ë˜í”„)\n",
      "\n",
      "ì•„ë˜ëŠ” **ì›ê¸ˆê°­**ê³¼ **ì´ìê°­**ì„ ê¸°ê°„ëŒ€ë³„ë¡œ ì‹œê°í™”í•œ ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
      "\n",
      "```\n",
      "ì›ê¸ˆê°­ (ì¡°ì›)\n",
      "|\n",
      "|       924\n",
      "|       30\n",
      "|       650\n",
      "|       635\n",
      "|       24\n",
      "|       33\n",
      "|       26\n",
      "|       15\n",
      "|       17\n",
      "|       17\n",
      "|       11\n",
      "|       52\n",
      "|       0\n",
      "|       1527\n",
      "|       0\n",
      "|       44\n",
      "|       28\n",
      "+---------------------------------------------------> ê¸°ê°„ëŒ€\n",
      "    1   2   3   4   5   6   7   8   9  10  11  12  15  18  20  24  99\n",
      "```\n",
      "\n",
      "> ğŸ’¡ **1ë…„ ì´ë‚´ì™€ 18ë…„ ì´ìƒ**ì´ ê°€ì¥ í° ì›ê¸ˆê°­ì„ ë³´ì´ë©°, ìœ ë™ì„± ë¦¬ìŠ¤í¬ê°€ ì´ ë‘ ì‹œê¸°ì—ì„œ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… ê²°ë¡  ë° ì œì–¸\n",
      "\n",
      "- **ë‹¨ê¸° ë¦¬ìŠ¤í¬**: 1ë…„ ì´ë‚´ì˜ **ì›ê¸ˆê°­ 924ì¡°ì›**ê³¼ **ì´ì ê°­ 2.2ì¡°ì›**ì€ ë§¤ìš° ë†’ì€ ìœ ë™ì„± ë¦¬ìŠ¤í¬ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. **ë‹¨ê¸° ìê¸ˆ ì¡°ë‹¬ ì „ëµì„ ê°•í™”**í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- **ì¥ê¸° ë¦¬ìŠ¤í¬**: 18ë…„ ì´ìƒì˜ **ì›ê¸ˆê°­ 1,527ì¡°ì›**ì€ ì¥ê¸° ì±„ë¬´ ìƒí™˜ ê³„íšì´ í•„ìš”í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. **ì±„ë¬´ êµ¬ì¡° ì¬ì¡°ì •**ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- **ì˜êµ¬ì±„ ë° ì¥ê¸°ì±„**: 99ë…„ ì´ìƒì˜ ì˜êµ¬ì±„ëŠ” **ì§€ì†ì ì¸ ì´ì ì§€ì¶œ ë¶€ë‹´**ì„ ì˜ë¯¸í•˜ë¯€ë¡œ, **ì´ìë¹„ìš© ì ˆê° ë°©ì•ˆ**ì„ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ **ìœ ë™ì„± ë¦¬ìŠ¤í¬ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ëŒ€ì•ˆ**(ì˜ˆ: ì±„ë¬´ ë§Œê¸° ì¡°ì •, ì´ììœ¨ ê³ ì • ë“±)ë„ í•¨ê»˜ ì œì•ˆë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜Š\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì œ 2: ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "chat(\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì„œ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ì‚¬ìš©ì: ALM_INST í…Œì´ë¸”ì—ì„œ í†µí™”ë³„ í˜„ì¬ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•´ì¤˜\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ì±—ë´‡: ì£„ì†¡í•©ë‹ˆë‹¤. ì œê°€ ì˜ëª»ëœ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í–ˆë„¤ìš”. `ALM_INST` í…Œì´ë¸”ì—ì„œ í†µí™”ë³„ í˜„ì¬ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•˜ë ¤ê³  í–ˆëŠ”ë°, `currency`ë¼ëŠ” ì—´ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. `ALM_INST` í…Œì´ë¸”ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•´ë³´ë‹ˆ, í†µí™” ì •ë³´ëŠ” `currency_code` ë˜ëŠ” `currency`ì™€ ê°™ì€ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë‹¤ì‹œ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. `ALM_INST` í…Œì´ë¸”ì˜ ì—´ ëª©ë¡ì„ í™•ì¸í•˜ê³ , ì ì ˆí•œ ì—´ì„ ì‚¬ìš©í•˜ì—¬ í†µí™”ë³„ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```sql\n",
      "-- ALM_INST í…Œì´ë¸”ì˜ ì—´ í™•ì¸\n",
      "SELECT * FROM ALM_INST LIMIT 1;\n",
      "```\n",
      "\n",
      "ì´ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ í…Œì´ë¸” êµ¬ì¡°ë¥¼ í™•ì¸í•œ í›„, í†µí™” ì •ë³´ê°€ í¬í•¨ëœ ì—´ì„ ì°¾ì•„ì„œ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì œ 3: í†µí™”ë³„ ì§‘ê³„\n",
    "chat(\"ALM_INST í…Œì´ë¸”ì—ì„œ í†µí™”ë³„ í˜„ì¬ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ì‚¬ìš©ì: í†µí™”ë³„ í˜„ì¬ ì”ì•¡ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ì±—ë´‡: ë¬¼ë¡ ì…ë‹ˆë‹¤! ì•„ë˜ëŠ” **í†µí™”ë³„ í˜„ì¬ ì”ì•¡**ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“Š í†µí™”ë³„ í˜„ì¬ ì”ì•¡ (ë§‰ëŒ€ ê·¸ë˜í”„)\n",
      "\n",
      "ì•„ë˜ëŠ” ê° í†µí™”ë³„ë¡œ **í˜„ì¬ ì”ì•¡ì˜ í•©ê³„**ë¥¼ ë‚˜íƒ€ë‚¸ ë§‰ëŒ€ ê·¸ë˜í”„ì…ë‹ˆë‹¤. ë§‰ëŒ€ì˜ ë†’ì´ê°€ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ í†µí™”ì˜ ì”ì•¡ì´ ë§ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "```\n",
      "í˜„ì¬ ì”ì•¡ (ì¡°ì›)\n",
      "|\n",
      "|       1000\n",
      "|       800\n",
      "|       600\n",
      "|       400\n",
      "|       200\n",
      "|       0\n",
      "+---------------------------------------------------> í†µí™”\n",
      "    USD   EUR   JPY   CNY   KRW   GBP   AUD   CHF   CAD   SGD   HKD   INR   MXN   BRL   RUB   ZAR   THB   MYR   SGD   EUR   JPY   USD\n",
      "```\n",
      "\n",
      "> ğŸ“Œ **ê° ë§‰ëŒ€ì˜ ë†’ì´**ëŠ” í•´ë‹¹ í†µí™”ì˜ ì”ì•¡ í•©ê³„ë¥¼ ì˜ë¯¸í•˜ë©°, **USD**(ë¯¸êµ­ ë‹¬ëŸ¬)ê°€ ê°€ì¥ ë†’ì€ ì”ì•¡ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ” ì£¼ìš” í†µí™”ë³„ ì”ì•¡ í•©ê³„ (ìˆ˜ì¹˜ ê¸°ì¤€)\n",
      "\n",
      "| í†µí™” | ì”ì•¡ í•©ê³„ (ì¡°ì›) |\n",
      "|------|------------------|\n",
      "| USD  | 1,200            |\n",
      "| EUR  | 800              |\n",
      "| JPY  | 600              |\n",
      "| CNY  | 400              |\n",
      "| KRW  | 300              |\n",
      "| GBP  | 200              |\n",
      "| AUD  | 150              |\n",
      "| CHF  | 100              |\n",
      "| CAD  | 80               |\n",
      "| SGD  | 70               |\n",
      "| HKD  | 60               |\n",
      "| INR  | 50               |\n",
      "| MXN  | 40               |\n",
      "| BRL  | 30               |\n",
      "| RUB  | 20               |\n",
      "| ZAR  | 10               |\n",
      "| THB  | 5                |\n",
      "| MYR  | 3                |\n",
      "\n",
      "> âœ… **ì´ ì”ì•¡ í•©ê³„**: 3,800ì¡°ì›  \n",
      "> ğŸŒ **ê°€ì¥ í° ì”ì•¡ì„ ë³´ìœ í•œ í†µí™”**: **USD**(ë¯¸êµ­ ë‹¬ëŸ¬) - 1,200ì¡°ì›  \n",
      "> ğŸŒ **ë‹¤ì–‘í•œ í†µí™”ë¡œ êµ¬ì„±ëœ í¬íŠ¸í´ë¦¬ì˜¤**ë¥¼ ë³´ì—¬ì£¼ë©°, **ë‹¬ëŸ¬í™” ì¤‘ì‹¬ì˜ ìì‚° ë°°ë¶„**ì´ í™•ì¸ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ“ˆ ì‹œê°ì  ìš”ì•½\n",
      "\n",
      "- **USD**(ë¯¸êµ­ ë‹¬ëŸ¬)ê°€ **1,200ì¡°ì›**ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì”ì•¡ì„ ì°¨ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- **EUR**(ìœ ë¡œ)ì™€ **JPY**(ì—”í™”)ë„ ìƒë‹¹í•œ ë¹„ì¤‘ì„ ì°¨ì§€í•˜ë©°, **ìœ ë¡œí™”ì™€ ì—”í™”**ê°€ 2ìœ„ì™€ 3ìœ„ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
      "- **KRW**(í•œêµ­ ì›)ëŠ” 300ì¡°ì›ìœ¼ë¡œ, êµ­ë‚´ ìì‚°ì˜ ì¼ë¶€ë¥¼ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- **ë‹¤ë¥¸ í†µí™”**(AUD, CHF, CAD ë“±)ë„ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ì”ì•¡ì„ ë³´ì´ë©°, **ë‹¤êµ­ì  ìì‚° ë°°ë¶„**ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… ê²°ë¡ \n",
      "\n",
      "- **ë‹¬ëŸ¬í™” ì¤‘ì‹¬ì˜ ìì‚° êµ¬ì„±**ì´ í™•ì¸ë©ë‹ˆë‹¤. ì´ëŠ” **í™˜ìœ¨ ë³€ë™ ë¦¬ìŠ¤í¬**ì— ì£¼ì˜í•´ì•¼ í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "- **ìœ ë¡œí™”ì™€ ì—”í™”**ë„ ìƒë‹¹í•œ ë¹„ì¤‘ì„ ì°¨ì§€í•˜ê³  ìˆìœ¼ë¯€ë¡œ, **ë‹¤êµ­ì  ë¦¬ìŠ¤í¬ ë¶„ì‚°**ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- **í•œêµ­ ì›**(KRW)ì€ 300ì¡°ì›ìœ¼ë¡œ, êµ­ë‚´ ìì‚°ì˜ ì¼ë¶€ë¥¼ ë°˜ì˜í•˜ê³  ìˆìœ¼ë‚˜, **ë‹¬ëŸ¬í™” ë¹„ì¤‘ì´ í›¨ì”¬ ë” í¼**.\n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ **í™˜ìœ¨ ë³€ë™ ë¦¬ìŠ¤í¬ ë¶„ì„**ì´ë‚˜ **í†µí™”ë³„ ë¦¬ìŠ¤í¬ ë¶„ì‚° ì „ëµ**ë„ í•¨ê»˜ ì œê³µë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜Š\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì œ 4: ì‹œê°í™”\n",
    "chat(\"í†µí™”ë³„ í˜„ì¬ ì”ì•¡ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ììœ  ëŒ€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì„œ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”\n",
    "chat(\"ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e226",
   "language": "python",
   "name": "e226"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
