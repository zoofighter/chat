{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALM ë°ì´í„° ë¶„ì„ ì±—ë´‡\n",
    "## LM Studio Qwen + LangChain Function Calling\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë¡œì»¬ LM Studioì˜ Qwen ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ALM ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # MacOS\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ\n",
    "DB_PATH = 'simple.db'\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„±\"\"\"\n",
    "    return sqlite3.connect(DB_PATH)\n",
    "\n",
    "def get_table_info():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    \n",
    "    table_info = {}\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        columns = cursor.fetchall()\n",
    "        table_info[table_name] = [col[1] for col in columns]  # ì»¬ëŸ¼ëª…ë§Œ ì¶”ì¶œ\n",
    "    \n",
    "    conn.close()\n",
    "    return table_info\n",
    "\n",
    "# í…Œì´ë¸” ì •ë³´ í™•ì¸\n",
    "tables = get_table_info()\n",
    "print(\"ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\")\n",
    "for table_name, columns in tables.items():\n",
    "    print(f\"\\n{table_name}: {len(columns)}ê°œ ì»¬ëŸ¼\")\n",
    "    print(f\"  ì£¼ìš” ì»¬ëŸ¼: {', '.join(columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LM Studio ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM Studio ì„¤ì •\n",
    "LM_STUDIO_BASE_URL = \"http://localhost:1234/v1\"\n",
    "LM_STUDIO_API_KEY = \"lm-studio\"  # LM StudioëŠ” ì‹¤ì œ API í‚¤ ë¶ˆí•„ìš”\n",
    "\n",
    "# LangChain ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” (LM Studio í˜¸í™˜)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=LM_STUDIO_BASE_URL,\n",
    "    api_key=LM_STUDIO_API_KEY,\n",
    "    temperature=0.1,\n",
    "    model=\"qwen\",  # LM Studioì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ëª…\n",
    ")\n",
    "\n",
    "print(\"LM Studio ì—°ê²° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"Base URL: {LM_STUDIO_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL ì‹¤í–‰ ë° ë¶„ì„ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "    \n",
    "    Args:\n",
    "        query: ì‹¤í–‰í•  SQL ì¿¼ë¦¬\n",
    "    \n",
    "    Returns:\n",
    "        ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (data, columns, row_count í¬í•¨)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": df.to_dict('records'),\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"row_count\": len(df),\n",
    "            \"dataframe\": df\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"data\": [],\n",
    "            \"columns\": [],\n",
    "            \"row_count\": 0\n",
    "        }\n",
    "\n",
    "def search_alm_contracts(filters: Optional[Dict] = None, limit: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    ALM ê³„ì•½ ì •ë³´ ê²€ìƒ‰\n",
    "    \n",
    "    Args:\n",
    "        filters: í•„í„° ì¡°ê±´ (ì˜ˆ: {\"CURRENCY_CD\": \"KRW\"})\n",
    "        limit: ê²°ê³¼ ì œí•œ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"SELECT * FROM ALM_INST\"\n",
    "    \n",
    "    if filters:\n",
    "        conditions = [f\"{k} = '{v}'\" for k, v in filters.items()]\n",
    "        query += \" WHERE \" + \" AND \".join(conditions)\n",
    "    \n",
    "    query += f\" LIMIT {limit}\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ê²€ìƒ‰ ê²°ê³¼: {result['row_count']}ê±´\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def analyze_liquidity_gap(scenario_no: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "    \n",
    "    Args:\n",
    "        scenario_no: ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸\n",
    "    \n",
    "    Returns:\n",
    "        ë¶„ì„ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        TIME_BAND,\n",
    "        SUM(GAP_PRN_TOTAL) as ì´_ì›ê¸ˆê°­,\n",
    "        SUM(GAP_INT_TOTAL) as ì´_ì´ìê°­,\n",
    "        COUNT(*) as ê±´ìˆ˜\n",
    "    FROM NFAR_LIQ_GAP_310524\n",
    "    \"\"\"\n",
    "    \n",
    "    if scenario_no is not None:\n",
    "        query += f\" WHERE SCENARIO_NO = {scenario_no}\"\n",
    "    \n",
    "    query += \" GROUP BY TIME_BAND ORDER BY TIME_BAND\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ìœ ë™ì„± ê°­ ë¶„ì„ ê²°ê³¼:\\n\\n{df.to_string()}\\n\\nì´ {result['row_count']}ê°œ ê¸°ê°„ëŒ€\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_exchange_rate(currency: str, date: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    í™˜ìœ¨ ì •ë³´ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        currency: í†µí™” ì½”ë“œ (ì˜ˆ: USD, EUR)\n",
    "        date: ì¡°íšŒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)\n",
    "    \n",
    "    Returns:\n",
    "        í™˜ìœ¨ ì •ë³´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM NFA_EXCH_RATE_HIST WHERE UNIT_CURRENCY_CD = '{currency}'\"\n",
    "    \n",
    "    if date:\n",
    "        query += f\" AND EFFECTIVE_DATE = '{date}'\"\n",
    "    \n",
    "    query += \" ORDER BY EFFECTIVE_DATE DESC LIMIT 10\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"{currency} í™˜ìœ¨ ì •ë³´:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_interest_rate(rate_cd: int, term: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    ê¸ˆë¦¬ ì •ë³´ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        rate_cd: ê¸ˆë¦¬ ì½”ë“œ\n",
    "        term: ê¸ˆë¦¬ ê¸°ê°„\n",
    "    \n",
    "    Returns:\n",
    "        ê¸ˆë¦¬ ì •ë³´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM NFA_IRC_RATE_HIST WHERE INT_RATE_CD = {rate_cd}\"\n",
    "    \n",
    "    if term is not None:\n",
    "        query += f\" AND INT_RATE_TERM = {term}\"\n",
    "    \n",
    "    query += \" ORDER BY EFFECTIVE_DATE DESC LIMIT 10\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"ê¸ˆë¦¬ ì •ë³´:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "def get_aggregate_stats(table_name: str, group_by: str, aggregate_col: str) -> str:\n",
    "    \"\"\"\n",
    "    ì§‘ê³„ í†µê³„ ì¡°íšŒ\n",
    "    \n",
    "    Args:\n",
    "        table_name: í…Œì´ë¸”ëª…\n",
    "        group_by: ê·¸ë£¹í™” ì»¬ëŸ¼\n",
    "        aggregate_col: ì§‘ê³„ ì»¬ëŸ¼\n",
    "    \n",
    "    Returns:\n",
    "        í†µê³„ ê²°ê³¼ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        {group_by},\n",
    "        COUNT(*) as ê±´ìˆ˜,\n",
    "        SUM({aggregate_col}) as í•©ê³„,\n",
    "        AVG({aggregate_col}) as í‰ê· ,\n",
    "        MIN({aggregate_col}) as ìµœì†Œ,\n",
    "        MAX({aggregate_col}) as ìµœëŒ€\n",
    "    FROM {table_name}\n",
    "    GROUP BY {group_by}\n",
    "    ORDER BY í•©ê³„ DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        df = result[\"dataframe\"]\n",
    "        return f\"{table_name} í…Œì´ë¸” {group_by}ë³„ {aggregate_col} ì§‘ê³„:\\n\\n{df.to_string()}\"\n",
    "    else:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "\n",
    "print(\"SQL í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì‹œê°í™” í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# DEPRECATED: ì‹œê°í™” ì œê±°ë¨ (TODO 4)\n",
    "# í•„ìš”ì‹œ ë‚˜ì¤‘ì— ì¬í™œì„±í™” ê°€ëŠ¥\n",
    "\n",
    "def visualize_query_result(query: str, chart_type: str = 'bar', \n",
    "                          x_col: Optional[str] = None, \n",
    "                          y_col: Optional[str] = None,\n",
    "                          title: Optional[str] = None) -> str:\n",
    "    \n",
    "    ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì‹œê°í™”\n",
    "    \n",
    "    Args:\n",
    "        query: SQL ì¿¼ë¦¬\n",
    "        chart_type: ì°¨íŠ¸ íƒ€ì… (bar, line, pie, scatter)\n",
    "        x_col: Xì¶• ì»¬ëŸ¼ëª…\n",
    "        y_col: Yì¶• ì»¬ëŸ¼ëª…\n",
    "        title: ì°¨íŠ¸ ì œëª©\n",
    "    \n",
    "    Returns:\n",
    "        ì‹œê°í™” ì™„ë£Œ ë©”ì‹œì§€\n",
    "    \n",
    "    result = execute_sql_query(query)\n",
    "    \n",
    "    if not result[\"success\"]:\n",
    "        return f\"ì˜¤ë¥˜ ë°œìƒ: {result['error']}\"\n",
    "    \n",
    "    df = result[\"dataframe\"]\n",
    "    \n",
    "    if df.empty:\n",
    "        return \"ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # x, y ì»¬ëŸ¼ ìë™ ì„ íƒ\n",
    "    if x_col is None:\n",
    "        x_col = df.columns[0]\n",
    "    if y_col is None and len(df.columns) > 1:\n",
    "        y_col = df.columns[1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    if chart_type == 'bar':\n",
    "        plt.bar(df[x_col].astype(str), df[y_col])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    elif chart_type == 'line':\n",
    "        plt.plot(df[x_col], df[y_col], marker='o')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    elif chart_type == 'pie':\n",
    "        plt.pie(df[y_col], labels=df[x_col], autopct='%1.1f%%')\n",
    "    elif chart_type == 'scatter':\n",
    "        plt.scatter(df[x_col], df[y_col])\n",
    "    \n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col if y_col else '')\n",
    "    plt.title(title if title else f\"{y_col} by {x_col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # í…Œì´ë¸”ë„ í•¨ê»˜ ì¶œë ¥\n",
    "    print(\"\\në°ì´í„° í…Œì´ë¸”:\")\n",
    "    print(df.to_string())\n",
    "    \n",
    "    return f\"ì°¨íŠ¸ ìƒì„± ì™„ë£Œ! ({chart_type} ì°¨íŠ¸, {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸)\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"ì‹œê°í™” í•¨ìˆ˜ ë¹„í™œì„±í™”ë¨ (TODO 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangChain Tools ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic ëª¨ë¸ ì •ì˜ (ì…ë ¥ ìŠ¤í‚¤ë§ˆ)\n",
    "class SearchContractsInput(BaseModel):\n",
    "    filters_json: str = Field(default=\"\", description=\"JSON í˜•ì‹ì˜ í•„í„° ì¡°ê±´\")\n",
    "\n",
    "class LiquidityGapInput(BaseModel):\n",
    "    scenario_no: str = Field(default=\"\", description=\"ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸\")\n",
    "\n",
    "class ExchangeRateInput(BaseModel):\n",
    "    currency_and_date: str = Field(description=\"í†µí™”ì½”ë“œ ë˜ëŠ” 'í†µí™”ì½”ë“œ,ë‚ ì§œ'\")\n",
    "\n",
    "class InterestRateInput(BaseModel):\n",
    "    rate_info: str = Field(description=\"ê¸ˆë¦¬ì½”ë“œ ë˜ëŠ” 'ê¸ˆë¦¬ì½”ë“œ,ê¸°ê°„'\")\n",
    "\n",
    "class AggregateStatsInput(BaseModel):\n",
    "    params: str = Field(description=\"'í…Œì´ë¸”ëª…,ê·¸ë£¹ì»¬ëŸ¼,ì§‘ê³„ì»¬ëŸ¼'\")\n",
    "\n",
    "# TODO 4: VisualizeInput ë° _visualize_data ì œê±°ë¨\n",
    "\n",
    "# ë„êµ¬ í•¨ìˆ˜ë“¤\n",
    "def _search_alm_contracts(filters_json: str = \"\") -> str:\n",
    "    \"\"\"ALM ê³„ì•½ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    filters = json.loads(filters_json) if filters_json else None\n",
    "    return search_alm_contracts(filters)\n",
    "\n",
    "def _analyze_liquidity_gap(scenario_no: str = \"\") -> str:\n",
    "    \"\"\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    scenario = int(scenario_no) if scenario_no else None\n",
    "    return analyze_liquidity_gap(scenario)\n",
    "\n",
    "def _get_exchange_rate(currency_and_date: str) -> str:\n",
    "    \"\"\"í™˜ìœ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = currency_and_date.split(',')\n",
    "    currency = parts[0].strip()\n",
    "    date = parts[1].strip() if len(parts) > 1 else None\n",
    "    return get_exchange_rate(currency, date)\n",
    "\n",
    "def _get_interest_rate(rate_info: str) -> str:\n",
    "    \"\"\"ê¸ˆë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = rate_info.split(',')\n",
    "    rate_cd = int(parts[0].strip())\n",
    "    term = int(parts[1].strip()) if len(parts) > 1 else None\n",
    "    return get_interest_rate(rate_cd, term)\n",
    "\n",
    "def _get_aggregate_stats(params: str) -> str:\n",
    "    \"\"\"í…Œì´ë¸”ì˜ ì§‘ê³„ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    parts = params.split(',')\n",
    "    if len(parts) != 3:\n",
    "        return \"ì˜¤ë¥˜: ì •í™•íˆ 3ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤\"\n",
    "    return get_aggregate_stats(parts[0].strip(), parts[1].strip(), parts[2].strip())\n",
    "\n",
    "# StructuredToolë¡œ ë„êµ¬ ìƒì„± (visualize_data ì œê±°ë¨)\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        func=_search_alm_contracts,\n",
    "        name=\"search_alm_contracts\",\n",
    "        description=\"ALM ê³„ì•½ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. filters_json: JSON í˜•ì‹ì˜ í•„í„° ì¡°ê±´ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´\",\n",
    "        args_schema=SearchContractsInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_analyze_liquidity_gap,\n",
    "        name=\"analyze_liquidity_gap\",\n",
    "        description=\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•©ë‹ˆë‹¤. scenario_no: ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)\",\n",
    "        args_schema=LiquidityGapInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_exchange_rate,\n",
    "        name=\"get_exchange_rate\",\n",
    "        description=\"í™˜ìœ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. currency_and_date: í†µí™”ì½”ë“œ ë˜ëŠ” 'í†µí™”ì½”ë“œ,ë‚ ì§œ'\",\n",
    "        args_schema=ExchangeRateInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_interest_rate,\n",
    "        name=\"get_interest_rate\",\n",
    "        description=\"ê¸ˆë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. rate_info: ê¸ˆë¦¬ì½”ë“œ ë˜ëŠ” 'ê¸ˆë¦¬ì½”ë“œ,ê¸°ê°„'\",\n",
    "        args_schema=InterestRateInput\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=_get_aggregate_stats,\n",
    "        name=\"get_aggregate_stats\",\n",
    "        description=\"í…Œì´ë¸”ì˜ ì§‘ê³„ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. params: 'í…Œì´ë¸”ëª…,ê·¸ë£¹ì»¬ëŸ¼,ì§‘ê³„ì»¬ëŸ¼'\",\n",
    "        args_schema=AggregateStatsInput\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"ì´ {len(tools)}ê°œì˜ ë„êµ¬ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "for tool_item in tools:\n",
    "    print(f\"  - {tool_item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Agent ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. ALMAgent í´ë˜ìŠ¤ ì •ì˜ (TODO 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALMAgent:\n",
    "    \"\"\"\n",
    "    ALM ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ReAct íŒ¨í„´ ì—ì´ì „íŠ¸\n",
    "    \n",
    "    ê¸°ëŠ¥:\n",
    "    - ë°˜ë³µì  ë„êµ¬ í˜¸ì¶œ ë° ì¶”ë¡  (TODO 1)\n",
    "    - ëŒ€í™” ì´ë ¥ ê´€ë¦¬\n",
    "    - ì‹¤í–‰ ë¡œê¹… ë° ë””ë²„ê¹…\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            llm: LLM ì¸ìŠ¤í„´ìŠ¤\n",
    "            tools: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.verbose = verbose\n",
    "        self.max_iterations = 10\n",
    "    \n",
    "    def _log(self, message: str):\n",
    "        \"\"\"verbose ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥\"\"\"\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "    \n",
    "    def run(self, user_input: str, chat_history: list = None) -> str:\n",
    "        \"\"\"\n",
    "        ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ (TODO 1: ë°˜ë³µì  ReAct ë£¨í”„)\n",
    "        \n",
    "        Args:\n",
    "            user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "            chat_history: ëŒ€í™” ì´ë ¥\n",
    "        \n",
    "        Returns:\n",
    "            ìµœì¢… ì‘ë‹µ\n",
    "        \"\"\"\n",
    "        if chat_history is None:\n",
    "            chat_history = []\n",
    "        \n",
    "        # ë©”ì‹œì§€ êµ¬ì„± (TODO 2: ë¶„ë¦¬ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)\n",
    "        system_message = SystemMessage(content=SYSTEM_PROMPT)\n",
    "        \n",
    "        # ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "        enhanced_prompt = f\"\"\"{user_input}\n",
    "\n",
    "ë¶„ì„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:\n",
    "1. í•„ìš”í•œ ì •ë³´ íŒŒì•…\n",
    "2. ì ì ˆí•œ ë„êµ¬ë¡œ ë°ì´í„° ì¡°íšŒ\n",
    "3. ì¶”ê°€ ì •ë³´ í•„ìš”ì‹œ ë‹¤ë¥¸ ë„êµ¬ ì‚¬ìš©\n",
    "4. ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€\"\"\"\n",
    "        \n",
    "        messages = [system_message]\n",
    "        messages.extend(chat_history)\n",
    "        messages.append(HumanMessage(content=enhanced_prompt))\n",
    "        \n",
    "        # ReAct ë°˜ë³µ ë£¨í”„ (TODO 1)\n",
    "        iteration = 0\n",
    "        tool_log = []\n",
    "        \n",
    "        while iteration < self.max_iterations:\n",
    "            iteration += 1\n",
    "            self._log(f\"\\n{'='*60}\")\n",
    "            self._log(f\"ğŸ”„ Iteration {iteration}\")\n",
    "            self._log(f\"{'='*60}\")\n",
    "            \n",
    "            # LLM ì¶”ë¡ \n",
    "            response = self.llm_with_tools.invoke(messages)\n",
    "            \n",
    "            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "            if not hasattr(response, 'tool_calls') or not response.tool_calls:\n",
    "                self._log(\"âœ“ ë¶„ì„ ì™„ë£Œ\")\n",
    "                return self._format_response(response.content, tool_log)\n",
    "            \n",
    "            # ë„êµ¬ ì‹¤í–‰ (í•œ ë²ˆì— í•˜ë‚˜ì”© - TODO 1ì˜ í•µì‹¬)\n",
    "            tool_call = response.tool_calls[0]\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            \n",
    "            self._log(f\"ğŸ”§ ë„êµ¬: {tool_name}\")\n",
    "            self._log(f\"ğŸ“ ì¸ì: {tool_args}\")\n",
    "            \n",
    "            # ë„êµ¬ ì‹¤í–‰\n",
    "            observation = self._execute_tool(tool_name, tool_args)\n",
    "            \n",
    "            # ë¡œê·¸ ê¸°ë¡\n",
    "            tool_log.append({\n",
    "                'iteration': iteration,\n",
    "                'tool': tool_name,\n",
    "                'success': not observation.startswith('ì˜¤ë¥˜')\n",
    "            })\n",
    "            \n",
    "            self._log(f\"ğŸ“Š ê²°ê³¼: {observation[:100]}...\")\n",
    "            \n",
    "            # ê´€ì°° ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‹¤ìŒ ë°˜ë³µì—ì„œ LLMì´ ì´ ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ìŒ í–‰ë™ ê²°ì •)\n",
    "            messages.append(HumanMessage(\n",
    "                content=f\"[ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ - Iteration {iteration}]\\n\"\n",
    "                       f\"ë„êµ¬: {tool_name}\\n\"\n",
    "                       f\"ê²°ê³¼:\\n{observation}\\n\\n\"\n",
    "                       f\"ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ì„¸ìš”.\"\n",
    "            ))\n",
    "        \n",
    "        return \"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    def _execute_tool(self, tool_name: str, tool_args: dict) -> str:\n",
    "        \"\"\"ë„êµ¬ ì‹¤í–‰\"\"\"\n",
    "        tool = self.tools.get(tool_name)\n",
    "        \n",
    "        if not tool:\n",
    "            return f\"ì˜¤ë¥˜: '{tool_name}' ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        try:\n",
    "            return tool.invoke(tool_args)\n",
    "        except Exception as e:\n",
    "            return f\"ì˜¤ë¥˜: {tool_name} ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {str(e)}\"\n",
    "    \n",
    "    def _format_response(self, content: str, tool_log: list) -> str:\n",
    "        \"\"\"ìµœì¢… ì‘ë‹µ í¬ë§·íŒ…\"\"\"\n",
    "        if not self.verbose or not tool_log:\n",
    "            return content\n",
    "        \n",
    "        summary = f\"\\n\\n{'='*60}\\nğŸ“‹ ì‹¤í–‰ ìš”ì•½\\n{'='*60}\\n\"\n",
    "        summary += f\"ì´ {len(tool_log)}ê°œ ë„êµ¬ ì‹¤í–‰\\n\"\n",
    "        \n",
    "        for log in tool_log:\n",
    "            status = \"âœ“\" if log['success'] else \"âœ—\"\n",
    "            summary += f\"  {status} [{log['iteration']}] {log['tool']}\\n\"\n",
    "        \n",
    "        return content + summary\n",
    "\n",
    "print(\"ALMAgent í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Agent ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (TODO 3)\n",
    "alm_agent = ALMAgent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ ALM Agent ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "print(f\"  - ë„êµ¬: {len(tools)}ê°œ\")\n",
    "print(f\"  - ìµœëŒ€ ë°˜ë³µ: {alm_agent.max_iterations}íšŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (TODO 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì—­í• , ê¸°ëŠ¥, ì§€ì¹¨ ì •ì˜\n",
    "SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ ALM(ìì‚°ë¶€ì±„ê´€ë¦¬) ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\n",
    "1. ALM_INST - ALM ê³„ì•½ ì •ë³´ (í†µí™”, ì”ì•¡, ê¸ˆë¦¬, ë§Œê¸°ì¼ ë“±)\n",
    "2. NFAR_LIQ_GAP_310524 - ìœ ë™ì„± ê°­ ë¶„ì„ (ì›ê¸ˆê°­, ì´ìê°­, ê¸°ê°„ëŒ€ë³„)\n",
    "3. NFAT_LIQ_INDEX_SUMMARY_M - ìœ ë™ì„± ì§€ìˆ˜ ìš”ì•½\n",
    "4. NFA_EXCH_RATE_HIST - í™˜ìœ¨ ì´ë ¥\n",
    "5. NFA_IRC_RATE_HIST - ê¸ˆë¦¬ ì´ë ¥\n",
    "6. orders_summary - ì£¼ë¬¸ ìš”ì•½\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "1. search_alm_contracts - ALM ê³„ì•½ ê²€ìƒ‰\n",
    "2. analyze_liquidity_gap - ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "3. get_exchange_rate - í™˜ìœ¨ ì •ë³´ ì¡°íšŒ\n",
    "4. get_interest_rate - ê¸ˆë¦¬ ì •ë³´ ì¡°íšŒ\n",
    "5. get_aggregate_stats - í…Œì´ë¸” ì§‘ê³„ í†µê³„\n",
    "\n",
    "ì‘ì—… ì§€ì¹¨:\n",
    "- ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”\n",
    "- í•„ìš”í•œ ê²½ìš° ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "- ê²°ê³¼ëŠ” í…Œì´ë¸”ê³¼ ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”\n",
    "- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”\n",
    "\"\"\"\n",
    "\n",
    "# ìœ ì € í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ - ë™ì  ì§ˆë¬¸ ë‚´ìš©\n",
    "USER_PROMPT_TEMPLATE = \"\"\"{user_question}\n",
    "\n",
    "ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMì— ë„êµ¬ ë°”ì¸ë”© (ìµœì‹  ë°©ì‹)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ê°„ë‹¨í•œ ì±„íŒ… í•¨ìˆ˜ (Agent ì—†ì´ ì§ì ‘ êµ¬í˜„)\n",
    "def run_agent(user_input: str, chat_history: list = None) -> str:\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  í•„ìš”ì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œ\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        chat_history: ëŒ€í™” ì´ë ¥\n",
    "    \n",
    "    Returns:\n",
    "        ì‘ë‹µ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    system_message = \"\"\"ë‹¹ì‹ ì€ ALM(ìì‚°ë¶€ì±„ê´€ë¦¬) ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”:\n",
    "1. ALM_INST - ALM ê³„ì•½ ì •ë³´ (í†µí™”, ì”ì•¡, ê¸ˆë¦¬, ë§Œê¸°ì¼ ë“±)\n",
    "2. NFAR_LIQ_GAP_310524 - ìœ ë™ì„± ê°­ ë¶„ì„ (ì›ê¸ˆê°­, ì´ìê°­, ê¸°ê°„ëŒ€ë³„)\n",
    "3. NFAT_LIQ_INDEX_SUMMARY_M - ìœ ë™ì„± ì§€ìˆ˜ ìš”ì•½\n",
    "4. NFA_EXCH_RATE_HIST - í™˜ìœ¨ ì´ë ¥\n",
    "5. NFA_IRC_RATE_HIST - ê¸ˆë¦¬ ì´ë ¥\n",
    "6. orders_summary - ì£¼ë¬¸ ìš”ì•½\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "ê²°ê³¼ëŠ” í…Œì´ë¸”, ê·¸ë˜í”„, ê·¸ë¦¬ê³  ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\n",
    "\n",
    "í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "    # ë©”ì‹œì§€ êµ¬ì„±\n",
    "    messages = [SystemMessage(content=system_message)]\n",
    "    messages.extend(chat_history)\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    \n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Tool calls í™•ì¸\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        # ë„êµ¬ ì‹¤í–‰\n",
    "        tool_results = []\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            \n",
    "            # í•´ë‹¹ ë„êµ¬ ì°¾ê¸°\n",
    "            tool_func = None\n",
    "            for t in tools:\n",
    "                if t.name == tool_name:\n",
    "                    tool_func = t\n",
    "                    break\n",
    "            \n",
    "            if tool_func:\n",
    "                try:\n",
    "                    # ë„êµ¬ ì‹¤í–‰\n",
    "                    result = tool_func.invoke(tool_args)\n",
    "                    tool_results.append(f\"\\n[{tool_name} ì‹¤í–‰ ê²°ê³¼]\\n{result}\")\n",
    "                except Exception as e:\n",
    "                    tool_results.append(f\"\\n[{tool_name} ì˜¤ë¥˜]\\n{str(e)}\")\n",
    "        \n",
    "        # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        if tool_results:\n",
    "            final_prompt = f\"{user_input}\\n\\në„êµ¬ ì‹¤í–‰ ê²°ê³¼:{''.join(tool_results)}\\n\\nìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "            messages_final = [SystemMessage(content=system_message)]\n",
    "            messages_final.append(HumanMessage(content=final_prompt))\n",
    "            final_response = llm.invoke(messages_final)\n",
    "            return final_response.content\n",
    "    \n",
    "    # Tool callì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì‘ë‹µ ë°˜í™˜\n",
    "    return response.content\n",
    "\n",
    "print(\"Agent ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëŒ€í™” ì´ë ¥ ì €ì¥\n",
    "chat_history = []\n",
    "\n",
    "def chat(user_input: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì±—ë´‡ ì‘ë‹µ ìƒì„± (TODO 3: ALMAgent ì‚¬ìš©)\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    \"\"\"\n",
    "    global chat_history\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ‘¤ ì‚¬ìš©ì: {user_input}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # ìƒˆë¡œìš´ ALMAgent ì‚¬ìš© (TODO 1, 3)\n",
    "        response = alm_agent.run(user_input, chat_history)\n",
    "        \n",
    "        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        chat_history.append(AIMessage(content=response))\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ¤– ì±—ë´‡: {response}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def reset_chat():\n",
    "    \"\"\"ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    print(\"âœ“ ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”ë¨\")\n",
    "\n",
    "print(\"ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"\\nì‚¬ìš© ì˜ˆì‹œ:\")\n",
    "print(\"  chat('ALM ê³„ì•½ ì¤‘ KRW í†µí™” ê³„ì•½ì„ ë³´ì—¬ì¤˜')\")\n",
    "print(\"  chat('ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì¤˜')\")\n",
    "print(\"  chat('USD í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜')\")\n",
    "print(\"  reset_chat()  # ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ì´ë ¥ ì €ì¥\n",
    "chat_history = []\n",
    "\n",
    "def chat(user_input: str):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì±—ë´‡ ì‘ë‹µ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        user_input: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    \"\"\"\n",
    "    global chat_history\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ì‚¬ìš©ì: {user_input}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Agent ì‹¤í–‰\n",
    "        response = run_agent(user_input, chat_history)\n",
    "        \n",
    "        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        chat_history.append(AIMessage(content=response))\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ì±—ë´‡: {response}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"\\nì‚¬ìš© ì˜ˆì‹œ:\")\n",
    "print(\"  chat('ALM ê³„ì•½ ì¤‘ KRW í†µí™” ê³„ì•½ì„ ë³´ì—¬ì¤˜')\")\n",
    "print(\"  chat('ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì¤˜')\")\n",
    "print(\"  chat('USD í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ì¤˜')\")\n",
    "print(\"  chat('í†µí™”ë³„ ì”ì•¡ì„ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í…ŒìŠ¤íŠ¸ - ì˜ˆì œ ì§ˆì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 1: ALM ê³„ì•½ ê²€ìƒ‰\n",
    "chat(\"ALM_INST í…Œì´ë¸”ì—ì„œ ì²˜ìŒ 5ê°œ ê³„ì•½ì„ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 2: ìœ ë™ì„± ê°­ ë¶„ì„\n",
    "chat(\"ìœ ë™ì„± ê°­ì„ ë¶„ì„í•´ì„œ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 3: í†µí™”ë³„ ì§‘ê³„\n",
    "chat(\"ALM_INST í…Œì´ë¸”ì—ì„œ í†µí™”ë³„ í˜„ì¬ ì”ì•¡ í•©ê³„ë¥¼ ê³„ì‚°í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 4: ì‹œê°í™”\n",
    "chat(\"í†µí™”ë³„ í˜„ì¬ ì”ì•¡ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ììœ  ëŒ€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì„œ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”\n",
    "chat(\"ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
